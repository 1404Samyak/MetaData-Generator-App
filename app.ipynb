{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196e6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document as DocxDocument\n",
    "import pytesseract\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import io\n",
    "import fitz\n",
    "from docx.opc.constants import RELATIONSHIP_TYPE as RT\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31897c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58c6d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\" # Path set in environment variables for tesseract to work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e34008",
   "metadata": {},
   "source": [
    "### Function to extract full text and all inline images from pdf and docx as txt files wont contain images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "182ddc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_inline_images(uploaded_file):\n",
    "    suffix = Path(uploaded_file.name).suffix.lower()\n",
    "    text = \"\"\n",
    "    image_list = []\n",
    "    ocr_texts_per_image = []\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:\n",
    "        tmp_file.write(uploaded_file.read())\n",
    "        tmp_file_path = tmp_file.name\n",
    "\n",
    "    try:\n",
    "        if suffix == \".pdf\":\n",
    "            try:\n",
    "                reader = PdfReader(tmp_file_path)\n",
    "                text = \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "            except Exception:\n",
    "                text = \"\"\n",
    "            pdf_doc = fitz.open(tmp_file_path)\n",
    "            for page in pdf_doc:\n",
    "                images = page.get_images(full=False)\n",
    "                for img in images:\n",
    "                    xref = img[0] if isinstance(img, tuple) else img\n",
    "                    base_image = pdf_doc.extract_image(xref)\n",
    "                    image_data = base_image[\"image\"]\n",
    "                    image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "                    image_list.append(image)\n",
    "                    ocr_img_text = pytesseract.image_to_string(image)\n",
    "                    ocr_texts_per_image.append(ocr_img_text)\n",
    "        elif suffix == \".docx\":\n",
    "            doc = DocxDocument(tmp_file_path)\n",
    "            text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "            rels = doc.part._rels\n",
    "            for rel in rels:\n",
    "                rel = rels[rel]\n",
    "                if rel.reltype == RT.IMAGE:\n",
    "                    image_data = rel.target_part.blob\n",
    "                    image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "                    image_list.append(image)\n",
    "                    ocr_img_text = pytesseract.image_to_string(image)\n",
    "                    ocr_texts_per_image.append(ocr_img_text)\n",
    "        elif suffix == \".txt\":\n",
    "            with open(tmp_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            text = f\"Unsupported file type: {suffix}\"\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(tmp_file_path)\n",
    "        except PermissionError:\n",
    "            pass\n",
    "\n",
    "    return {\n",
    "        \"text\": text.strip(),\n",
    "        \"images\": image_list,\n",
    "        \"ocr_texts_per_image\": ocr_texts_per_image\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724eb9b",
   "metadata": {},
   "source": [
    "### Function to chunk the large text into chunks of size 2800 assuming 1 token is approximately 4 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "881af969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_by_tokens(text, max_tokens=700):\n",
    "    chunk_size = 2800\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        current_length += len(word) + 1\n",
    "        if current_length >= chunk_size:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b757f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)nth_super_ugly_number:\n",
      "  problem:\n",
      "    description: >\n",
      "      Find the nth super ugly number, where a super ugly number is a positive integer \n",
      "      whose prime factors are only from the given list `primes`.\n",
      "\n",
      "    input:\n",
      "      n: The index (1-based) of the super ugly number to return.\n",
      "      primes: A list of prime numbers used to generate super ugly numbers.\n",
      "\n",
      "    output:\n",
      "      dp[n]: The nth super ugly number.\n",
      "\n",
      "  definitions:\n",
      "    dp[i]: >\n",
      "      The i-th super ugly number, where:\n",
      "      - dp[1] is initialized to 1 (the first super ugly number),\n",
      "      - dp[i] is built using previously computed dp values and the prime list.\n",
      "\n",
      "    a[j]: >\n",
      "      The index pointer for each prime number `primes[j]`, initially pointing to dp[1].\n",
      "      - It tracks which multiple of a given prime to consider next.\n",
      "\n",
      "  approach:\n",
      "    type: Dynamic Programming (with multiple moving pointers)\n",
      "    steps:\n",
      "      - Initialize `dp` as a vector of size (n+1), with dp[1] = 1.\n",
      "      - Initialize an index pointer array `a` of size m (number of primes), all set to 1.\n",
      "      - For each i from 2 to n:\n",
      "        - Set val = infinity.\n",
      "        - For each prime:\n",
      "          - Compute `dp[a[j]] * primes[j]`, and keep track of the minimum of all.\n",
      "        - Set dp[i] = min value found.\n",
      "        - For each prime again:\n",
      "          - If the product equals dp[i], increment the respective pointer a[j] to avoid duplicates.\n",
      "\n",
      "  explanation:\n",
      "    - At every step, you are trying to generate the next smallest number \n",
      "      whose prime divisors are limited to the provided list `primes`.\n",
      "    - You generate the next candidates by multiplying previous dp values with each prime.\n",
      "    - The multiple pointers ensure you avoid recomputing duplicate values \n",
      "      and efficiently progress each sequence.\n",
      "    - The result is always increasing, and duplicates are prevented by the condition \n",
      "      `if dp[a[j]] * primes[j] == dp[i]`.\n",
      "\n",
      "  complexity:\n",
      "    time: O(n * k), where k is the number of primes.\n",
      "    space: O(n + k), for storing the dp array and pointer list.\n",
      "\n",
      "  output:\n",
      "    return_value: dp[n]\n",
      "\n",
      "  notes:\n",
      "    - Use of `1LL` ensures multiplication stays in long long to avoid integer overflow.\n",
      "    - Final result is cast to int before returning, since the result fits in 32-bit int.\n",
      "\n",
      "2)ountNumberOfLIS\n",
      "description: >\n",
      "  Computes the number of Longest Increasing Subsequences (LIS) in a given array using Dynamic Programming.\n",
      "  For each element, tracks both the length of the LIS ending there and how many such LIS exist.\n",
      "\n",
      "input:\n",
      "  - n: Number of elements in the array\n",
      "  - a: Array of integers of length n\n",
      "\n",
      "output:\n",
      "  - count: Total number of LIS of maximum length\n",
      "\n",
      "steps:\n",
      "  1. Read Input:\n",
      "    - Read `n` (number of elements)\n",
      "    - Read array `a` of length `n`\n",
      "\n",
      "  2. Initialize Arrays:\n",
      "    - dp[i] = Length of the LIS ending at index i\n",
      "    - c[i] = Number of LIS of length dp[i] ending at index i\n",
      "    - Both initialized to 1, since each element is a LIS of length 1\n",
      "\n",
      "  3. Fill dp and c using nested loops:\n",
      "    for i in 1 to n-1:\n",
      "      for j in 0 to i-1:\n",
      "        if a[j] < a[i]:\n",
      "          if dp[j] + 1 > dp[i]:\n",
      "            dp[i] = dp[j] + 1\n",
      "            c[i] = c[j]        # new longer LIS found, take over count\n",
      "          else if dp[j] + 1 == dp[i]:\n",
      "            c[i] += c[j]       # same-length LIS found, accumulate count\n",
      "\n",
      "    explanation: >\n",
      "      - For each a[i], check all previous elements a[j].\n",
      "      - If a[j] < a[i], a[i] can extend the LIS ending at a[j].\n",
      "      - Update dp[i] to the maximum LIS length, and c[i] to track how many LIS of that length end at i.\n",
      "\n",
      "  4. Find max LIS length:\n",
      "    - ans = max(dp[0 to n-1])\n",
      "\n",
      "  5. Count total number of LIS:\n",
      "    - For all i such that dp[i] == ans:\n",
      "        - Accumulate c[i] into `count`\n",
      "\n",
      "  6. Output:\n",
      "    - Print or return `count` as total number of LIS of maximum length\n",
      "\n",
      "time_complexity: O(n^2)\n",
      "space_complexity: O(n)\n",
      "\n",
      "variables:\n",
      "  - dp: vector<ll> of size n, stores LIS lengths\n",
      "  - c:  vector<ll> of size n, stores LIS counts\n",
      "  - ans: maximum LIS length\n",
      "  - count: total number of LIS of length ans\n",
      "\n",
      "example:\n",
      "  input:\n",
      "    n: 6\n",
      "    a: [1, 3, 5, 4, 7, 2]\n",
      "  dp: [1, 2, 3, 3, 4, 2]\n",
      "  c:  [1, 1, 1, 1, 2, 1]\n",
      "  max_length: 4\n",
      "  result: 2  # Two LIS of length 4: [1,3,4,7] and [1,3,5,7]\n",
      "\n",
      "notes:\n",
      "  - This algorithm only counts LIS, not reconstructs them.\n",
      "  - Can be extended to print all LIS using additional tracking structures.\n",
      "\n",
      "3)problem: Longest Common Subsequence (LCS)\n",
      "   function: longestCommonSubsequence(s, t)\n",
      "   dp_definition:\n",
      "     dp[i][j]: Length of LCS between s[0..i-1] and t[0..j-1]\n",
      "   recurrence:\n",
      "     if s[i-1] == t[j-1]:\n",
      "       dp[i][j] = 1 + dp[i-1][j-1]\n",
      "     else:\n",
      "       dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
      "   base_cases:\n",
      "     - dp[0][j] = 0 for all j (empty s)\n",
      "     - dp[i][0] = 0 for all i (empty t)\n",
      "   result: dp[n][m] (length of LCS between s and t)\n",
      "   time_complexity: O(n * m)\n",
      "   space_complexity: O(n * m)\n",
      "   use_case: Core building block for many string problems.\n",
      "\n",
      "---\n",
      "\n",
      "2. problem: Longest Palindromic Subsequence (LPS)\n",
      "   function: longestPalindromicSubsequence(s)\n",
      "   idea: >\n",
      "     A palindrome reads the same forwards and backwards. So the LPS of s is simply\n",
      "     the LCS of s and its reverse.\n",
      "   steps:\n",
      "     - Let rev = reverse(s)\n",
      "     - Compute LCS(s, rev)\n",
      "   reason: >\n",
      "     Characters that are common in the same order in both s and rev form a palindromic subsequence.\n",
      "   result: Length of the longest palindromic subsequence\n",
      "   example:\n",
      "     s: \"bbabcbcab\"\n",
      "     rev: \"bacbcbabb\"\n",
      "     lps_length: 7 (e.g., \"babcbab\")\n",
      "   time_complexity: O(n^2)\n",
      "\n",
      "---\n",
      "\n",
      "3. problem: Minimum Insertions to Make a String Palindromic\n",
      "   function: minInsertionsToMakePalindrome(s)\n",
      "   idea: >\n",
      "     The minimum number of insertions = s.length() - LPS(s)\n",
      "   reason: >\n",
      "     Once you know the longest palindromic subsequence, all the other characters must be matched by insertions.\n",
      "   formula: min_insertions = len(s) - longestPalindromicSubsequence(s)\n",
      "   example:\n",
      "     s: \"abcd\"\n",
      "     lps: 1 (\"a\", \"b\", \"c\", or \"d\")\n",
      "     result: 3 insertions (e.g., \"dcbabcd\")\n",
      "   time_complexity: O(n^2)\n",
      "\n",
      "---\n",
      "\n",
      "4. problem: Minimum Insertions to Convert s1 to s2\n",
      "   function: minInsertionsToConvert(s1, s2)\n",
      "   idea: >\n",
      "     Use LCS(s1, s2) to determine common part.\n",
      "     The number of insertions required = len(s2) - LCS(s1, s2)\n",
      "   reason: >\n",
      "     To make s1 into s2, insert the characters from s2 that are not in the LCS.\n",
      "   formula: insertions = len(s2) - LCS(s1, s2)\n",
      "   example:\n",
      "     s1: \"abc\"\n",
      "     s2: \"aebdc\"\n",
      "     LCS: \"abc\" → length 3\n",
      "     result: 2 insertions (\"e\" and \"d\")\n",
      "   time_complexity: O(n * m)\n",
      "\n",
      "---\n",
      "\n",
      "shared_base:\n",
      "  core_dp: LCS (Longest Common Subsequence)\n",
      "  recurrence:\n",
      "    if s[i-1] == t[j-1]:\n",
      "      dp[i][j] = 1 + dp[i-1][j-1]\n",
      "    else:\n",
      "      dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
      "  usage: >\n",
      "    All the above problems reuse this LCS DP as their base, either by comparing a string with its reverse\n",
      "    or comparing two different strings to determine how many characters are common or missing.\n",
      "\n",
      "AUTHOR: Samyak Mahapatra\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "with open(\"test.txt\", \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "uploaded_file = io.BytesIO(file_bytes)\n",
    "uploaded_file.name = \"test.txt\" \n",
    "\n",
    "result = extract_text_and_inline_images(uploaded_file)\n",
    "\n",
    "print(result['text'])\n",
    "print(result['images'])\n",
    "print(result['ocr_texts_per_image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3b153a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)nth_super_ugly_number: problem: description: > Find the nth super ugly number, where a super ugly number is a positive integer whose prime factors are only from the given list `primes`. input: n: The index (1-based) of the super ugly number to return. primes: A list of prime numbers used to generate super ugly numbers. output: dp[n]: The nth super ugly number. definitions: dp[i]: > The i-th super ugly number, where: - dp[1] is initialized to 1 (the first super ugly number), - dp[i] is built using previously computed dp values and the prime list. a[j]: > The index pointer for each prime number `primes[j]`, initially pointing to dp[1]. - It tracks which multiple of a given prime to consider next. approach: type: Dynamic Programming (with multiple moving pointers) steps: - Initialize `dp` as a vector of size (n+1), with dp[1] = 1. - Initialize an index pointer array `a` of size m (number of primes), all set to 1. - For each i from 2 to n: - Set val = infinity. - For each prime: - Compute `dp[a[j]] * primes[j]`, and keep track of the minimum of all. - Set dp[i] = min value found. - For each prime again: - If the product equals dp[i], increment the respective pointer a[j] to avoid duplicates. explanation: - At every step, you are trying to generate the next smallest number whose prime divisors are limited to the provided list `primes`. - You generate the next candidates by multiplying previous dp values with each prime. - The multiple pointers ensure you avoid recomputing duplicate values and efficiently progress each sequence. - The result is always increasing, and duplicates are prevented by the condition `if dp[a[j]] * primes[j] == dp[i]`. complexity: time: O(n * k), where k is the number of primes. space: O(n + k), for storing the dp array and pointer list. output: return_value: dp[n] notes: - Use of `1LL` ensures multiplication stays in long long to avoid integer overflow. - Final result is cast to int before returning, since the result fits in 32-bit int. 2)ountNumberOfLIS description: > Computes the number of Longest Increasing Subsequences (LIS) in a given array using Dynamic Programming. For each element, tracks both the length of the LIS ending there and how many such LIS exist. input: - n: Number of elements in the array - a: Array of integers of length n output: - count: Total number of LIS of maximum length steps: 1. Read Input: - Read `n` (number of elements) - Read array `a` of length `n` 2. Initialize Arrays: - dp[i] = Length of the LIS ending at index i - c[i] = Number of LIS of length dp[i] ending at index i - Both initialized to 1, since each element is a LIS of length 1 3. Fill dp and c using nested loops: for i in 1 to n-1: for j in 0 to i-1: if a[j] < a[i]: if dp[j] + 1 > dp[i]: dp[i] = dp[j] + 1 c[i] = c[j] # new longer LIS found, 2800\n",
      "take over count else if dp[j] + 1 == dp[i]: c[i] += c[j] # same-length LIS found, accumulate count explanation: > - For each a[i], check all previous elements a[j]. - If a[j] < a[i], a[i] can extend the LIS ending at a[j]. - Update dp[i] to the maximum LIS length, and c[i] to track how many LIS of that length end at i. 4. Find max LIS length: - ans = max(dp[0 to n-1]) 5. Count total number of LIS: - For all i such that dp[i] == ans: - Accumulate c[i] into `count` 6. Output: - Print or return `count` as total number of LIS of maximum length time_complexity: O(n^2) space_complexity: O(n) variables: - dp: vector<ll> of size n, stores LIS lengths - c: vector<ll> of size n, stores LIS counts - ans: maximum LIS length - count: total number of LIS of length ans example: input: n: 6 a: [1, 3, 5, 4, 7, 2] dp: [1, 2, 3, 3, 4, 2] c: [1, 1, 1, 1, 2, 1] max_length: 4 result: 2 # Two LIS of length 4: [1,3,4,7] and [1,3,5,7] notes: - This algorithm only counts LIS, not reconstructs them. - Can be extended to print all LIS using additional tracking structures. 3)problem: Longest Common Subsequence (LCS) function: longestCommonSubsequence(s, t) dp_definition: dp[i][j]: Length of LCS between s[0..i-1] and t[0..j-1] recurrence: if s[i-1] == t[j-1]: dp[i][j] = 1 + dp[i-1][j-1] else: dp[i][j] = max(dp[i-1][j], dp[i][j-1]) base_cases: - dp[0][j] = 0 for all j (empty s) - dp[i][0] = 0 for all i (empty t) result: dp[n][m] (length of LCS between s and t) time_complexity: O(n * m) space_complexity: O(n * m) use_case: Core building block for many string problems. --- 2. problem: Longest Palindromic Subsequence (LPS) function: longestPalindromicSubsequence(s) idea: > A palindrome reads the same forwards and backwards. So the LPS of s is simply the LCS of s and its reverse. steps: - Let rev = reverse(s) - Compute LCS(s, rev) reason: > Characters that are common in the same order in both s and rev form a palindromic subsequence. result: Length of the longest palindromic subsequence example: s: \"bbabcbcab\" rev: \"bacbcbabb\" lps_length: 7 (e.g., \"babcbab\") time_complexity: O(n^2) --- 3. problem: Minimum Insertions to Make a String Palindromic function: minInsertionsToMakePalindrome(s) idea: > The minimum number of insertions = s.length() - LPS(s) reason: > Once you know the longest palindromic subsequence, all the other characters must be matched by insertions. formula: min_insertions = len(s) - longestPalindromicSubsequence(s) example: s: \"abcd\" lps: 1 (\"a\", \"b\", \"c\", or \"d\") result: 3 insertions (e.g., \"dcbabcd\") time_complexity: O(n^2) --- 4. problem: Minimum Insertions to Convert s1 to s2 function: minInsertionsToConvert(s1, s2) idea: > Use LCS(s1, s2) to determine common part. The number of insertions required = len(s2) - LCS(s1, s2) reason: > To make s1 into s2, insert the characters 2807\n",
      "from s2 that are not in the LCS. formula: insertions = len(s2) - LCS(s1, s2) example: s1: \"abc\" s2: \"aebdc\" LCS: \"abc\" → length 3 result: 2 insertions (\"e\" and \"d\") time_complexity: O(n * m) --- shared_base: core_dp: LCS (Longest Common Subsequence) recurrence: if s[i-1] == t[j-1]: dp[i][j] = 1 + dp[i-1][j-1] else: dp[i][j] = max(dp[i-1][j], dp[i][j-1]) usage: > All the above problems reuse this LCS DP as their base, either by comparing a string with its reverse or comparing two different strings to determine how many characters are common or missing. AUTHOR: Samyak Mahapatra 582\n"
     ]
    }
   ],
   "source": [
    "chunks=chunk_text_by_tokens(result['text'])\n",
    "for chunk in chunks:\n",
    "    print(chunk,len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86c954",
   "metadata": {},
   "source": [
    "### Summarising with Groq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "749c97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_groq(text, api_key, model=\"llama-3.3-70b-versatile\", max_tokens=700):\n",
    "    llm = ChatGroq(model=model, api_key=api_key, max_tokens=max_tokens)\n",
    "    prompt = f\"Summarize the following text in detail,extract the meaningful sections of document like author names,important keywords etc, but keep the summary under {max_tokens} tokens:\\n\\n{text}\"\n",
    "    response = llm([\n",
    "        SystemMessage(content=\"You are a professional summarization assistant.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931c9c0",
   "metadata": {},
   "source": [
    "Hierarchical summarization is a technique designed to handle very large documents that exceed the token limits of language models like Groq’s Llama 3.3 70B Versatile. First, the document is divided into manageable chunks, and each chunk is individually summarized. Then, all these chunk summaries are combined and, if necessary, summarized again to produce a concise final summary within the model’s token limit. This approach ensures that important information from the entire document is retained and condensed efficiently, making it possible to generate high-quality summaries even for massive documents that would otherwise overwhelm the model’s input size. The main advantages are scalability, comprehensive coverage, and improved summary quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd00eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_pdf_text(full_text):\n",
    "    chunks = chunk_text_by_tokens(full_text, max_tokens=700)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarize_with_groq(chunk, api_key=GROQ_API_KEY, model=\"llama-3.3-70b-versatile\", max_tokens=700)\n",
    "        summaries.append(summary)\n",
    "    combined_summary = \"\\n\".join(summaries)\n",
    "    if len(summaries) > 1 or len(combined_summary.split()) > 700:\n",
    "        combined_summary = summarize_with_groq(combined_summary, api_key=GROQ_API_KEY, model=\"llama-3.3-70b-versatile\", max_tokens=700)\n",
    "    return combined_summary.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4748010a",
   "metadata": {},
   "source": [
    "### Function to generate Metadata using the summarised text by groq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a32eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata(summarized_text):\n",
    "    llm = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key=GROQ_API_KEY, max_tokens=700)\n",
    "    prompt = f\"\"\"\n",
    "You are a professional and wonderful metadata assistant.\n",
    "\n",
    "Analyze the following document summary and return structured metadata in JSON format with fields: \n",
    "- title\n",
    "- summary (at least 15-20 lines in detail covering all important points)\n",
    "- keywords (comma-separated)\n",
    "- topics (broad subject categories)\n",
    "- author (if mentioned)\n",
    "- document_type\n",
    "Extract and leverage the important sections of summary\n",
    "Document Summary:\n",
    "{summarized_text}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = llm([\n",
    "            SystemMessage(content=\"You are a metadata extraction assistant.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        st.error(f\"Metadata extraction failed: {e}\")\n",
    "        return '{\"error\": \"Metadata extraction failed.\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1692ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_ocr_text(ocr_text):\n",
    "    if not ocr_text.strip():\n",
    "        return \"No OCR content found to summarize.\"\n",
    "    llm = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key=GROQ_API_KEY)\n",
    "    prompt = (\n",
    "        \"You are a professional assistant. \"\n",
    "        \"Start your response with 'The following image ...'. \"\n",
    "        \"Summarize the following OCR-extracted content in a clear, well-organized, and visually appealing markdown format. \"\n",
    "        \"Your summary should include:\\n\"\n",
    "        \"- A short title or heading for the content\\n\"\n",
    "        \"- Key points or highlights as a bullet list\\n\"\n",
    "        \"- Detected names, dates, numbers, or keywords (if any)\\n\"\n",
    "        \"- A concise paragraph summarizing the main idea or purpose\\n\"\n",
    "        \"If the content is a graph or chart, explain axes and key trends. \"\n",
    "        \"If it's a table, highlight main comparisons or figures. \"\n",
    "        \"If it's a scanned paragraph, summarize the main idea. \"\n",
    "        \"Avoid assumptions. If content is unclear, mention it.\\n\\n\"\n",
    "        f\"OCR Text:\\n{ocr_text}\"\n",
    "    )\n",
    "    try:\n",
    "        response = llm([\n",
    "            SystemMessage(content=\"You summarize OCR-extracted content in structured markdown.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"OCR summarization failed: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2139281",
   "metadata": {},
   "source": [
    "### Testing each fuctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e8796",
   "metadata": {},
   "source": [
    "### 1)TXT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c39f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)nth_super_ugly_number:\n",
      "  problem:\n",
      "    description: >\n",
      "      Find the nth super ugly number, where a super ugly number is a positive integer \n",
      "      whose prime factors are only from the given list `primes`.\n",
      "\n",
      "    input:\n",
      "      n: The index (1-based) of the super ugly number to return.\n",
      "      primes: A list of prime numbers used to generate super ugly numbers.\n",
      "\n",
      "    output:\n",
      "      dp[n]: The nth super ugly number.\n",
      "\n",
      "  definitions:\n",
      "    dp[i]: >\n",
      "      The i-th super ugly number, where:\n",
      "      - dp[1] is initialized to 1 (the first super ugly number),\n",
      "      - dp[i] is built using previously computed dp values and the prime list.\n",
      "\n",
      "    a[j]: >\n",
      "      The index pointer for each prime number `primes[j]`, initially pointing to dp[1].\n",
      "      - It tracks which multiple of a given prime to consider next.\n",
      "\n",
      "  approach:\n",
      "    type: Dynamic Programming (with multiple moving pointers)\n",
      "    steps:\n",
      "      - Initialize `dp` as a vector of size (n+1), with dp[1] = 1.\n",
      "      - Initialize an index pointer array `a` of size m (number of primes), all set to 1.\n",
      "      - For each i from 2 to n:\n",
      "        - Set val = infinity.\n",
      "        - For each prime:\n",
      "          - Compute `dp[a[j]] * primes[j]`, and keep track of the minimum of all.\n",
      "        - Set dp[i] = min value found.\n",
      "        - For each prime again:\n",
      "          - If the product equals dp[i], increment the respective pointer a[j] to avoid duplicates.\n",
      "\n",
      "  explanation:\n",
      "    - At every step, you are trying to generate the next smallest number \n",
      "      whose prime divisors are limited to the provided list `primes`.\n",
      "    - You generate the next candidates by multiplying previous dp values with each prime.\n",
      "    - The multiple pointers ensure you avoid recomputing duplicate values \n",
      "      and efficiently progress each sequence.\n",
      "    - The result is always increasing, and duplicates are prevented by the condition \n",
      "      `if dp[a[j]] * primes[j] == dp[i]`.\n",
      "\n",
      "  complexity:\n",
      "    time: O(n * k), where k is the number of primes.\n",
      "    space: O(n + k), for storing the dp array and pointer list.\n",
      "\n",
      "  output:\n",
      "    return_value: dp[n]\n",
      "\n",
      "  notes:\n",
      "    - Use of `1LL` ensures multiplication stays in long long to avoid integer overflow.\n",
      "    - Final result is cast to int before returning, since the result fits in 32-bit int.\n",
      "\n",
      "2)ountNumberOfLIS\n",
      "description: >\n",
      "  Computes the number of Longest Increasing Subsequences (LIS) in a given array using Dynamic Programming.\n",
      "  For each element, tracks both the length of the LIS ending there and how many such LIS exist.\n",
      "\n",
      "input:\n",
      "  - n: Number of elements in the array\n",
      "  - a: Array of integers of length n\n",
      "\n",
      "output:\n",
      "  - count: Total number of LIS of maximum length\n",
      "\n",
      "steps:\n",
      "  1. Read Input:\n",
      "    - Read `n` (number of elements)\n",
      "    - Read array `a` of length `n`\n",
      "\n",
      "  2. Initialize Arrays:\n",
      "    - dp[i] = Length of the LIS ending at index i\n",
      "    - c[i] = Number of LIS of length dp[i] ending at index i\n",
      "    - Both initialized to 1, since each element is a LIS of length 1\n",
      "\n",
      "  3. Fill dp and c using nested loops:\n",
      "    for i in 1 to n-1:\n",
      "      for j in 0 to i-1:\n",
      "        if a[j] < a[i]:\n",
      "          if dp[j] + 1 > dp[i]:\n",
      "            dp[i] = dp[j] + 1\n",
      "            c[i] = c[j]        # new longer LIS found, take over count\n",
      "          else if dp[j] + 1 == dp[i]:\n",
      "            c[i] += c[j]       # same-length LIS found, accumulate count\n",
      "\n",
      "    explanation: >\n",
      "      - For each a[i], check all previous elements a[j].\n",
      "      - If a[j] < a[i], a[i] can extend the LIS ending at a[j].\n",
      "      - Update dp[i] to the maximum LIS length, and c[i] to track how many LIS of that length end at i.\n",
      "\n",
      "  4. Find max LIS length:\n",
      "    - ans = max(dp[0 to n-1])\n",
      "\n",
      "  5. Count total number of LIS:\n",
      "    - For all i such that dp[i] == ans:\n",
      "        - Accumulate c[i] into `count`\n",
      "\n",
      "  6. Output:\n",
      "    - Print or return `count` as total number of LIS of maximum length\n",
      "\n",
      "time_complexity: O(n^2)\n",
      "space_complexity: O(n)\n",
      "\n",
      "variables:\n",
      "  - dp: vector<ll> of size n, stores LIS lengths\n",
      "  - c:  vector<ll> of size n, stores LIS counts\n",
      "  - ans: maximum LIS length\n",
      "  - count: total number of LIS of length ans\n",
      "\n",
      "example:\n",
      "  input:\n",
      "    n: 6\n",
      "    a: [1, 3, 5, 4, 7, 2]\n",
      "  dp: [1, 2, 3, 3, 4, 2]\n",
      "  c:  [1, 1, 1, 1, 2, 1]\n",
      "  max_length: 4\n",
      "  result: 2  # Two LIS of length 4: [1,3,4,7] and [1,3,5,7]\n",
      "\n",
      "notes:\n",
      "  - This algorithm only counts LIS, not reconstructs them.\n",
      "  - Can be extended to print all LIS using additional tracking structures.\n",
      "\n",
      "3)problem: Longest Common Subsequence (LCS)\n",
      "   function: longestCommonSubsequence(s, t)\n",
      "   dp_definition:\n",
      "     dp[i][j]: Length of LCS between s[0..i-1] and t[0..j-1]\n",
      "   recurrence:\n",
      "     if s[i-1] == t[j-1]:\n",
      "       dp[i][j] = 1 + dp[i-1][j-1]\n",
      "     else:\n",
      "       dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
      "   base_cases:\n",
      "     - dp[0][j] = 0 for all j (empty s)\n",
      "     - dp[i][0] = 0 for all i (empty t)\n",
      "   result: dp[n][m] (length of LCS between s and t)\n",
      "   time_complexity: O(n * m)\n",
      "   space_complexity: O(n * m)\n",
      "   use_case: Core building block for many string problems.\n",
      "\n",
      "---\n",
      "\n",
      "2. problem: Longest Palindromic Subsequence (LPS)\n",
      "   function: longestPalindromicSubsequence(s)\n",
      "   idea: >\n",
      "     A palindrome reads the same forwards and backwards. So the LPS of s is simply\n",
      "     the LCS of s and its reverse.\n",
      "   steps:\n",
      "     - Let rev = reverse(s)\n",
      "     - Compute LCS(s, rev)\n",
      "   reason: >\n",
      "     Characters that are common in the same order in both s and rev form a palindromic subsequence.\n",
      "   result: Length of the longest palindromic subsequence\n",
      "   example:\n",
      "     s: \"bbabcbcab\"\n",
      "     rev: \"bacbcbabb\"\n",
      "     lps_length: 7 (e.g., \"babcbab\")\n",
      "   time_complexity: O(n^2)\n",
      "\n",
      "---\n",
      "\n",
      "3. problem: Minimum Insertions to Make a String Palindromic\n",
      "   function: minInsertionsToMakePalindrome(s)\n",
      "   idea: >\n",
      "     The minimum number of insertions = s.length() - LPS(s)\n",
      "   reason: >\n",
      "     Once you know the longest palindromic subsequence, all the other characters must be matched by insertions.\n",
      "   formula: min_insertions = len(s) - longestPalindromicSubsequence(s)\n",
      "   example:\n",
      "     s: \"abcd\"\n",
      "     lps: 1 (\"a\", \"b\", \"c\", or \"d\")\n",
      "     result: 3 insertions (e.g., \"dcbabcd\")\n",
      "   time_complexity: O(n^2)\n",
      "\n",
      "---\n",
      "\n",
      "4. problem: Minimum Insertions to Convert s1 to s2\n",
      "   function: minInsertionsToConvert(s1, s2)\n",
      "   idea: >\n",
      "     Use LCS(s1, s2) to determine common part.\n",
      "     The number of insertions required = len(s2) - LCS(s1, s2)\n",
      "   reason: >\n",
      "     To make s1 into s2, insert the characters from s2 that are not in the LCS.\n",
      "   formula: insertions = len(s2) - LCS(s1, s2)\n",
      "   example:\n",
      "     s1: \"abc\"\n",
      "     s2: \"aebdc\"\n",
      "     LCS: \"abc\" → length 3\n",
      "     result: 2 insertions (\"e\" and \"d\")\n",
      "   time_complexity: O(n * m)\n",
      "\n",
      "---\n",
      "\n",
      "shared_base:\n",
      "  core_dp: LCS (Longest Common Subsequence)\n",
      "  recurrence:\n",
      "    if s[i-1] == t[j-1]:\n",
      "      dp[i][j] = 1 + dp[i-1][j-1]\n",
      "    else:\n",
      "      dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
      "  usage: >\n",
      "    All the above problems reuse this LCS DP as their base, either by comparing a string with its reverse\n",
      "    or comparing two different strings to determine how many characters are common or missing.\n",
      "\n",
      "AUTHOR: Samyak Mahapatra\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "with open(\"test.txt\", \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "uploaded_file = io.BytesIO(file_bytes)\n",
    "uploaded_file.name = \"test.txt\" \n",
    "\n",
    "result = extract_text_and_inline_images(uploaded_file)\n",
    "\n",
    "print(result['text'])\n",
    "print(result['images'])\n",
    "print(result['ocr_texts_per_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e5d004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahap\\AppData\\Local\\Temp\\ipykernel_19852\\2390314035.py:4: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response = llm([\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary**\n",
      "\n",
      "The provided text discusses several problems related to dynamic programming, including finding the nth super ugly number, counting the number of Longest Increasing Subsequences (LIS) in an array, and calculating the Longest Common Subsequence (LCS) between two strings. \n",
      "\n",
      "**Key Points**\n",
      "\n",
      "1. **nth Super Ugly Number Problem**: The problem involves finding the nth super ugly number using dynamic programming with multiple moving pointers. The time complexity is O(n * k), where k is the number of primes, and the space complexity is O(n + k).\n",
      "2. **Counting Longest Increasing Subsequences (LIS) Problem**: The problem involves computing the number of LIS in a given array using dynamic programming. The approach tracks both the length of the LIS ending at each element and the number of such LIS.\n",
      "3. **Longest Common Subsequence (LCS) Problem**: The problem finds the length of the longest common subsequence between two strings using dynamic programming with a time complexity of O(n*m) and space complexity of O(n*m).\n",
      "4. **Longest Palindromic Subsequence (LPS) Problem**: The problem finds the length of the longest palindromic subsequence in a given string using the LCS function to find the LCS between the string and its reverse.\n",
      "5. **Minimum Insertions to Make a String Palindromic**: The problem finds the minimum number of insertions required to make a string palindromic using the LPS function.\n",
      "\n",
      "**Author and Keywords**\n",
      "\n",
      "* **Author**: Samyak Mahapatra (mentioned in one of the summaries)\n",
      "* **Keywords**: \n",
      "    + Dynamic Programming\n",
      "    + Super Ugly Number\n",
      "    + Longest Increasing Subsequence (LIS)\n",
      "    + Longest Common Subsequence (LCS)\n",
      "    + Longest Palindromic Subsequence (LPS)\n",
      "    + Minimum Insertions to Make a String Palindromic\n",
      "    + Prime Factors\n",
      "    + Time Complexity\n",
      "    + Space Complexity\n",
      "\n",
      "**Important Variables and Data Structures**\n",
      "\n",
      "* `dp`: Dynamic programming array\n",
      "* `a`: Index pointer array\n",
      "* `primes`: List of prime numbers\n",
      "* `n`: Index of the super ugly number to return\n",
      "* `c`: Array to store the number of LIS of length `dp[i]` ending at index `i`\n",
      "* `s` and `t`: Input strings for LCS and LPS problems\n",
      "* `rev`: Reverse of the input string for LPS problem\n",
      "\n",
      "**Time and Space Complexities**\n",
      "\n",
      "* **LIS**: O(n^2) time complexity, O(n) space complexity\n",
      "* **LCS**: O(n*m) time complexity, O(n*m) space complexity\n",
      "* **LPS**: O(n^2) time complexity\n",
      "* **Minimum Insertions to Make a String Palindromic**: O(n^2) time complexity\n",
      "* **nth Super Ugly Number**: O(n * k) time complexity, O(n + k) space complexity\n"
     ]
    }
   ],
   "source": [
    "response=summarize_pdf_text(result['text'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d47489e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted metadata in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Dynamic Programming Problems\",\n",
      "  \"summary\": \"The document discusses several dynamic programming problems, including finding the nth super ugly number, counting the number of Longest Increasing Subsequences (LIS) in an array, and calculating the Longest Common Subsequence (LCS) between two strings. The problems are solved using dynamic programming techniques with varying time and space complexities. The nth super ugly number problem uses multiple moving pointers with a time complexity of O(n * k) and space complexity of O(n + k). The LIS problem computes the number of LIS in a given array by tracking the length of the LIS ending at each element and the number of such LIS. The LCS problem finds the length of the longest common subsequence between two strings using dynamic programming with a time complexity of O(n*m) and space complexity of O(n*m). The Longest Palindromic Subsequence (LPS) problem finds the length of the longest palindromic subsequence in a given string using the LCS function to find the LCS between the string and its reverse. The Minimum Insertions to Make a String Palindromic problem finds the minimum number of insertions required to make a string palindromic using the LPS function. The problems involve various variables and data structures, including dynamic programming arrays, index pointer arrays, lists of prime numbers, and input strings. The time and space complexities of the problems are also discussed, including O(n^2) time complexity and O(n) space complexity for the LIS problem, O(n*m) time complexity and O(n*m) space complexity for the LCS problem, O(n^2) time complexity for the LPS problem, and O(n * k) time complexity and O(n + k) space complexity for the nth super ugly number problem.\",\n",
      "  \"keywords\": \"Dynamic Programming, Super Ugly Number, Longest Increasing Subsequence (LIS), Longest Common Subsequence (LCS), Longest Palindromic Subsequence (LPS), Minimum Insertions to Make a String Palindromic, Prime Factors, Time Complexity, Space Complexity\",\n",
      "  \"topics\": [\"Dynamic Programming\", \"Algorithms\", \"Computer Science\"],\n",
      "  \"author\": \"Samyak Mahapatra\",\n",
      "  \"document_type\": \"Technical Summary\"\n",
      "}\n",
      "```\n",
      "\n",
      "Note that I have condensed the information from the original document into a concise JSON object, while still maintaining the essential details and structure of the original text. Let me know if you would like me to make any adjustments!\n"
     ]
    }
   ],
   "source": [
    "metadata=generate_metadata(response)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415e117",
   "metadata": {},
   "source": [
    "### 2)PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa23ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tiger ( Panthera tigris ) is the largest member of the cat family and one of the world ’s most iconic \n",
      "and powerful predators. Easily recognized by its striking orange coat with black stripes, the tiger is \n",
      "native to various parts of Asia, inhabiting forests, grasslands, and mangrove swamps. Tigers are \n",
      "solitary and territorial animals, relying on stealth and strength to hunt prey such as deer, wild boar, \n",
      "and buffalo. Sadly, their populations have declined sharply due to habitat loss, poaching, and huma n-\n",
      "wildlife conflict, leaving fewer than 4,000 tigers in the wild today. As an endangered species and a \n",
      "keystone predator, the tiger plays a crucial role in maintaining the health of its ecosystem. Revered in \n",
      "many cultures as a symbol of strength and courag e, the tiger ’s survival depends on ongoing \n",
      "conservation efforts to protect both the species and its natural habitats.  \n",
      " \n",
      "The elephant is the largest living land animal, easily recognized by its massive body, long trunk, large \n",
      "ears, and ivory tusks.  Three sp ecies exist today: the African bush elephant, the African forest \n",
      "elephant, and the Asian elephant, each adapted to a range of habitats across Africa and Asia, \n",
      "including savannas, forests, and grasslands.  Elephants are highly intelligent, social creatures k nown \n",
      "for their strong family bonds and remarkable memories.  Female elephants, or cows, live in \n",
      "matriarchal herds with their young, while adult males are more solitary or form loose bachelor \n",
      "groups.  Their trunks serve many purposes, from picking up food and  water to communicating and \n",
      "expressing emotions.  Elephants are herbivores, feeding on grasses, leaves, fruits, and bark, and they \n",
      "play a crucial role as keystone species by shaping their ecosystems.  Sadly, elephant populations have \n",
      "declined due to habitat loss, poaching for ivory, and human -wildlife conflict, making their \n",
      "conservation a global priority.  Despite their size and strength, elephants are vulnerable and need \n",
      "protection to ensure their survival for future generations  \n",
      " \n",
      "The parrot is a vibrant and i ntelligent bird known for its strikingly colorful feathers, strong curved \n",
      "beak, and remarkable ability to mimic sounds, including human speech. Found mainly in tropical and \n",
      "subtropical regions, parrots thrive in a variety of habitats such as rainforests, w oodlands, and \n",
      "savannas. They are social creatures, often living in flocks and forming close bonds with their mates. \n",
      "\n",
      "Parrots use their zygodactyl feet —two toes facing forward and two backward —to skillfully grasp food \n",
      "and climb. Their diet typically consists  of seeds, fruits, nuts, and sometimes insects. Highly playful \n",
      "and curious, parrots are celebrated for their problem -solving skills and affectionate nature, making \n",
      "them popular pets. However, many parrot species face threats from habitat loss and the illeg al pet \n",
      "trade, leading to declining populations and highlighting the need for conservation efforts to protect \n",
      "these extraordinary birds.  \n",
      " \n",
      " \n",
      "The dog is a domesticated mammal known for its intelligence, loyalty, and companionship, making it \n",
      "one of humanity ’s oldest and most beloved animal partners. Dogs come in a vast variety of breeds, \n",
      "each with its own unique physical traits and behavioral tendencies, shaped by generations of \n",
      "selective breeding for specific tasks such as herding, hunting, guarding, or compan ionship. While \n",
      "breed can influence a dog ’s energy level, trainability, and temperament —for example, herding \n",
      "breeds are often energetic and attentive, while hounds may be more independent —every dog is also \n",
      "an individual with its own personality. Dogs are hi ghly social animals, forming strong bonds with \n",
      "humans and other animals, and they communicate through a combination of vocalizations, body \n",
      "language, and facial expressions. Their adaptability and eagerness to please have made them \n",
      "invaluable as working ani mals and cherished as pets in homes around the world. While genetics play \n",
      "a role in their behavior, a dog ’s upbringing, environment, and training are equally important in \n",
      "shaping its character and temperamen  \n",
      " \n",
      "AUTHOR: SAMYAK MAHAPATRA\n",
      "['Best.\\nSummer.\\nEver.\\n', 'It was the best of\\ntimes, it was the worst\\nof times, it was the age\\nof wisdom, it was the\\nage of foolishness...\\n', \"[choose you, And Fl choose\\n‘you over and over. Without\\n\\npause, without a doubt,\\nina heartbeat. I'll keep\\nchoosing you.\\n\\n\"]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "with open(\"test.pdf\", \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "uploaded_file = io.BytesIO(file_bytes)\n",
    "uploaded_file.name = \"test.pdf\" \n",
    "\n",
    "result = extract_text_and_inline_images(uploaded_file)\n",
    "\n",
    "print(result['text'])\n",
    "# print(result['images'])\n",
    "print(result['ocr_texts_per_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc83f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a detailed summary of the provided text, extracting meaningful sections, author names, and important keywords, all within the 700-token limit:\n",
      "\n",
      "The text describes three iconic species: the tiger, elephant, and parrot, highlighting their unique characteristics and the threats they face. The tiger, a powerful predator, is native to Asia and recognized by its distinctive orange coat with black stripes. However, its population has declined due to habitat loss, poaching, and human-wildlife conflict. The elephant, the largest living land animal, is highly intelligent and social, playing a crucial role in shaping its ecosystem. Unfortunately, elephant populations have also declined due to habitat loss, poaching, and human-wildlife conflict. The parrot, a vibrant and intelligent bird, is known for its colorful feathers and ability to mimic sounds.\n",
      "\n",
      "Important keywords extracted from the text include habitat loss, poaching, human-wildlife conflict, conservation, keystone species, ecosystem, intelligence, and social behavior. The author of the first part of the text is not specified, while the second part is written by Samyak Mahapatra.\n",
      "\n",
      "The conservation status of the mentioned species is as follows: the tiger is endangered with fewer than 4,000 individuals in the wild, the elephant has a declining population due to habitat loss, poaching, and human-wildlife conflict, and many parrot species face threats from habitat loss.\n",
      "\n",
      "The text also discusses the importance of conservation efforts for extraordinary birds affected by habitat loss and the illegal pet trade. It highlights the unique characteristics of dogs, known for their intelligence, loyalty, and companionship. Dogs come in various breeds, each with distinct physical and behavioral traits, shaped by selective breeding for tasks like herding, hunting, and companionship.\n",
      "\n",
      "Overall, the text emphasizes the need to protect iconic species and their habitats, addressing human-wildlife conflict and habitat loss to ensure their survival. It also provides an overview of the importance of conservation efforts and the unique characteristics of dogs, highlighting their value as working animals and beloved pets.\n",
      "\n",
      "Extracted information includes:\n",
      "\n",
      "* Species: Tiger, Elephant, Parrot, Dogs\n",
      "* Keywords: Habitat loss, Poaching, Human-wildlife conflict, Conservation, Keystone species, Ecosystem, Intelligence, Social behavior, Dog breeds, Loyalty, Companionship\n",
      "* Authors: Samyak Mahapatra (second part), unknown (first part)\n",
      "* Important sections: Description of tiger habitat and behavior, Elephant species and adaptations, Parrot characteristics and habitats, Conservation efforts, Dog breeds, Dog characteristics.\n"
     ]
    }
   ],
   "source": [
    "response=summarize_pdf_text(result['text'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "588b2660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following image appears to be a scanned paragraph or text excerpt with a short and enthusiastic message. \n",
      "### Summer Enthusiasm\n",
      "* The text expresses excitement about summer\n",
      "* The tone is positive and upbeat\n",
      "Detected keywords: Summer\n",
      "The main idea of this text is to convey that the speaker believes the current summer is the best one ever, expressing a high level of enthusiasm and excitement. However, the content is quite brief and lacks specific details, making it unclear what makes this summer stand out.\n",
      "The following image contains a scanned paragraph of text. \n",
      "### Introduction to a Timeless Tale\n",
      "* The passage describes a time of contrasting experiences\n",
      "* It highlights the coexistence of wisdom and foolishness\n",
      "* The text is a famous opening to a classic novel\n",
      "Detected keywords: wisdom, foolishness, best of times, worst of times. \n",
      "The main idea of this passage is to introduce a historical period marked by extremes, where good and bad, wisdom and foolishness, all existed simultaneously. The text appears to be the opening sentence of Charles Dickens' novel \"A Tale of Two Cities,\" setting the tone for a story that explores themes of duality and contradiction.\n",
      "The following image contains a scanned paragraph of text that appears to be a romantic declaration. \n",
      "### Content Summary\n",
      "* The speaker expresses their commitment to choosing the person they love\n",
      "* The choice is made without hesitation or doubt\n",
      "* The speaker promises to continue choosing this person\n",
      "Detected keywords: love, choice, commitment\n",
      "The main idea of this text is a heartfelt expression of devotion, where the speaker reaffirms their love and commitment to the person they care about, stating they will choose them repeatedly without any doubts. The text conveys a sense of certainty and permanence in the speaker's feelings.\n"
     ]
    }
   ],
   "source": [
    "for text in result['ocr_texts_per_image']:\n",
    "    print(summarize_ocr_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74e04ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted metadata in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Iconic Species and Conservation Efforts\",\n",
      "  \"summary\": \"The text describes three iconic species: the tiger, elephant, and parrot, highlighting their unique characteristics and the threats they face. The tiger, a powerful predator, is native to Asia and recognized by its distinctive orange coat with black stripes. However, its population has declined due to habitat loss, poaching, and human-wildlife conflict. The elephant, the largest living land animal, is highly intelligent and social, playing a crucial role in shaping its ecosystem. Unfortunately, elephant populations have also declined due to habitat loss, poaching, and human-wildlife conflict. The parrot, a vibrant and intelligent bird, is known for its colorful feathers and ability to mimic sounds. \\n\\nThe conservation status of the mentioned species is as follows: the tiger is endangered with fewer than 4,000 individuals in the wild, the elephant has a declining population due to habitat loss, poaching, and human-wildlife conflict, and many parrot species face threats from habitat loss. \\n\\nThe text also discusses the importance of conservation efforts for extraordinary birds affected by habitat loss and the illegal pet trade. It highlights the unique characteristics of dogs, known for their intelligence, loyalty, and companionship. Dogs come in various breeds, each with distinct physical and behavioral traits, shaped by selective breeding for tasks like herding, hunting, and companionship. \\n\\nOverall, the text emphasizes the need to protect iconic species and their habitats, addressing human-wildlife conflict and habitat loss to ensure their survival. It also provides an overview of the importance of conservation efforts and the unique characteristics of dogs, highlighting their value as working animals and beloved pets. \\n\\nThe text covers various important sections, including the description of tiger habitat and behavior, elephant species and adaptations, parrot characteristics and habitats, conservation efforts, dog breeds, and dog characteristics. \\n\\nIn conclusion, the text provides a comprehensive overview of iconic species, their unique characteristics, and the threats they face, as well as the importance of conservation efforts to protect these species and their habitats.\",\n",
      "  \"keywords\": \"habitat loss, poaching, human-wildlife conflict, conservation, keystone species, ecosystem, intelligence, social behavior, dog breeds, loyalty, companionship\",\n",
      "  \"topics\": [\"Wildlife Conservation\", \"Biology\", \"Ecology\", \"Animal Behavior\"],\n",
      "  \"author\": \"Samyak Mahapatra (second part), unknown (first part)\",\n",
      "  \"document_type\": \"Informative Article\"\n",
      "}\n",
      "```\n",
      "\n",
      "Note: The summary field has been expanded to cover all important points and sections of the original document summary, while maintaining a clear and concise structure. The keywords field includes all the important keywords extracted from the text, and the topics field provides broad subject categories related to the document. The author field mentions both the known and unknown authors, and the document_type field specifies the type of document.\n"
     ]
    }
   ],
   "source": [
    "metadata=generate_metadata(response)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5546f",
   "metadata": {},
   "source": [
    "### Docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30dd2d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and standard deviation are two fundamental statistical measures with distinct yet complementary properties. The mean, or average, represents the central tendency of a dataset, providing a single value that summarizes all the numbers in the set. It is sensitive to every value in the data, meaning that even a single extremely large or small value (an outlier) can significantly affect the mean. On the other hand, the standard deviation measures the amount of variation or dispersion in the dataset. A low standard deviation indicates that the data points are closely clustered around the mean, while a high standard deviation suggests that the values are spread out over a wider range. Both the mean and standard deviation are widely used in statistics to describe and compare datasets, and they are especially important in fields such as science, finance, and engineering for understanding patterns, consistency, and reliability in data. \n",
      "The z-test and p-value are important concepts in statistical hypothesis testing, each with distinct properties. The z-test is used to determine whether there is a significant difference between sample and population means, or between two sample means, especially when the sample size is large and the population variance is known. It assumes the data are normally distributed and calculates a z-score, which measures how many standard deviations a data point is from the mean. The p-value, on the other hand, is not a test itself but a probability that quantifies the strength of evidence against the null hypothesis. It represents the likelihood of obtaining a result at least as extreme as the observed one, assuming the null hypothesis is true. A small p-value suggests strong evidence against the null hypothesis, while a large p-value indicates weak evidence. Together, the z-test provides the test statistic and the p-value helps decide whether to reject or fail to reject the null hypothesis, making both essential tools for drawing conclusions from data in scientific research and data analysis.\n",
      "\n",
      "The 67-95-99 rule (more commonly known as the 68-95-99.7 rule or the empirical rule) describes how data is distributed in a normal (Gaussian) distribution. According to this rule, about 68% of the data falls within one standard deviation of the mean, about 95% falls within two standard deviations, and about 99.7% falls within three standard deviations. This means that for a bell-shaped Gaussian curve, the vast majority of values are clustered close to the mean, and very few are found far from it. The rule is widely used in statistics to quickly estimate the spread of data and to identify outliers or unusual observations. It only applies to data that is normally distributed and helps in understanding probabilities, making predictions, and setting thresholds in quality control and risk analysis\n",
      "\n",
      "\n",
      "A log-normal distribution is a continuous probability distribution in which the logarithm of the random variable is normally distributed. In other words, if a variable XX is log-normally distributed, then Y=ln⁡(X)Y=ln(X) follows a normal (Gaussian) distribution. This means that while the normal distribution can take both positive and negative values, the log-normal distribution only takes positive real values, making it especially useful for modeling data that cannot be negative and often displays a right-skewed, long-tailed pattern.\n",
      "The log-normal distribution commonly arises in situations where a quantity results from the multiplicative product of many independent, positive random variables—such as in modeling incomes, biological measurements, stock prices, and certain natural phenomena. Its probability density function is defined for x>0 and is characterized by two parameters: the mean (μμ) and standard deviation (σσ) of the variable’s natural logarithm, not of the variable itself.\n",
      "\n",
      "\n",
      "Probability is a concept in mathematics that describes how likely it is for a particular event to happen. It is expressed as a number between 0 and 1, where 0 means the event cannot happen and 1 means it is certain to happen. For instance, if you roll a standard six-sided die, the probability of getting a 3 is 1 out of 6, or about 0.167. Probability helps us make predictions and informed decisions in situations involving uncertainty, such as games of chance, weather forecasts, or financial investments. It provides a systematic way to quantify and reason about uncertainty in everyday life and scientific studies.\n",
      "\n",
      "The Poisson distribution is a discrete probability distribution that describes the likelihood of a certain number of events occurring within a fixed interval of time or space, given that these events happen independently and at a constant average rate. It is defined by a single parameter, lambda (λ), which represents the mean number of occurrences in the interval. The Poisson distribution is commonly used to model rare or random events, such as the number of emails received in an hour, calls at a call center, or radioactive decays in a sample. The probability of observing exactly k events in the interval is given by the formula P(k)=λke−λk!P(k)=k!λke−λ, where k is a non-negative integer. This distribution is especially useful when dealing with count data and helps in predicting or understanding the frequency of random, independent events over time or space\n",
      "['Parameters\\n\\na, b integers with b > a\\nnm=b-a+1\\n\\n‘Support ke {a,atl,...,b—1,b}\\nPMF 1\\nn\\nCDF |k| -a+1\\nn\\n\\nMean a+b\\n\\n2\\nMedian a+b\\n\\n2\\n‘Mode N/A\\n\\n', 'Notation | Lognormal( 4, ” )\\n\\nParameters 4 € ( — 00,-+00 ) (logarithm of scale),\\n\\no>0\\n\\nSupport | z €(0,+00)\\n\\nPDF 1 (Ine —p)?\\n——— ep(-\\nsoir 20?\\n\\n', 'vo €0 70 TO 00\\n', 'jl = Mean\\nO = Standard Deviation\\nm = 3.14159\\ne & 2.71828\\n', 'Z=\\n\\nP17 P2\\n\\nPA-P)Ge+\\n\\n4)\\n\\nnz\\n\\n_ ™P1t\\n\\nr N2P2\\n\\nn, +4\\n\\n+ No\\n', '5. Mean\\n\\n. sum of terms\\nnumber of terms\\n\\n6. Probability\\n\\n+ P(x) = #2ffavorableoutcomes\\n#of possible outcomes\\n', '‘rma to estimate sample standard deviation\\n\\n', '']\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "with open(\"test.docx\", \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "uploaded_file = io.BytesIO(file_bytes)\n",
    "uploaded_file.name = \"test.docx\" \n",
    "\n",
    "result = extract_text_and_inline_images(uploaded_file)\n",
    "\n",
    "print(result['text'])\n",
    "# print(result['images'])\n",
    "print(result['ocr_texts_per_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2aafac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a detailed summary of the provided text, extracting meaningful sections, keywords, and concepts, all within the 700-token limit:\n",
      "\n",
      "The text discusses fundamental statistical concepts, including the mean, standard deviation, z-test, and p-value. These measures are crucial in statistics, particularly in fields like science, finance, and engineering. The mean represents the central tendency of a dataset, while the standard deviation measures the variation or dispersion. The z-test determines significant differences between sample and population means, and the p-value quantifies the strength of evidence against the null hypothesis.\n",
      "\n",
      "The text also introduces the 67-95-99 rule, also known as the empirical rule, which describes the distribution of data in a normal (Gaussian) distribution. This rule states that about 68% of data falls within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three standard deviations.\n",
      "\n",
      "In addition to these concepts, the text explores probability distributions, including the log-normal distribution and the Poisson distribution. The log-normal distribution is a continuous probability distribution where the logarithm of the random variable is normally distributed, making it suitable for modeling data that cannot be negative and often displays a right-skewed pattern. The Poisson distribution is a discrete probability distribution that describes the likelihood of a certain number of events occurring within a fixed interval of time or space.\n",
      "\n",
      "**Extracted Information:**\n",
      "\n",
      "* **Important Keywords:** mean, standard deviation, z-test, p-value, log-normal distribution, Poisson distribution, probability, empirical rule, 67-95-99 rule.\n",
      "* **Author Names:** Not mentioned in the text.\n",
      "* **Key Concepts:**\n",
      "\t+ Mean: represents the central tendency of a dataset.\n",
      "\t+ Standard deviation: measures the variation or dispersion in a dataset.\n",
      "\t+ Z-test: determines significant differences between sample and population means.\n",
      "\t+ P-value: quantifies the strength of evidence against the null hypothesis.\n",
      "\t+ Log-Normal Distribution: a continuous probability distribution where the logarithm of the random variable is normally distributed.\n",
      "\t+ Poisson Distribution: a discrete probability distribution that describes the likelihood of a certain number of events occurring within a fixed interval of time or space.\n",
      "* **Fields of Application:** science, finance, engineering, statistical research, data analysis, quality control, risk analysis, uncertainty, random events, count data.\n",
      "\n",
      "**Meaningful Sections:**\n",
      "\n",
      "* Introduction to the mean and standard deviation as fundamental statistical measures.\n",
      "* Explanation of the z-test and p-value in statistical hypothesis testing.\n",
      "* Description of the 67-95-99 rule and its application in understanding probabilities and making predictions.\n",
      "* Introduction to the log-normal distribution and its application in modeling data that cannot be negative.\n",
      "* Introduction to the Poisson distribution and its application in modeling rare or random events.\n"
     ]
    }
   ],
   "source": [
    "response=summarize_pdf_text(result['text'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d53389d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following image appears to be a scanned paragraph describing parameters of a discrete uniform distribution. \n",
      "### Discrete Uniform Distribution Parameters\n",
      "* The parameters are defined by two integers `a` and `b` where `b > a`.\n",
      "* The number of possible values `n` is calculated as `n = b - a + 1`.\n",
      "* The support of the distribution is the set of integers from `a` to `b`.\n",
      "* Key statistics include:\n",
      "  + Mean: `(a + b) / 2`\n",
      "  + Median: `(a + b) / 2`\n",
      "  + Mode: Not applicable (N/A)\n",
      "* Detected keywords: discrete uniform distribution, parameters, mean, median, mode.\n",
      "The main idea of this content is to outline the parameters and key statistics of a discrete uniform distribution, which is a probability distribution where every possible outcome has an equal likelihood of occurring. The distribution is defined by two integers `a` and `b`, and various statistics such as mean, median, and mode are calculated based on these parameters. The mode is noted as not applicable, indicating that the distribution does not have a single most likely value.\n",
      "The following image appears to be a mathematical notation for a probability distribution, specifically a lognormal distribution. \n",
      "\n",
      "### Lognormal Distribution Notation\n",
      "* Notation: Lognormal(4, 0)\n",
      "* Parameters: \n",
      "  + μ (logarithm of scale) = 4\n",
      "  + σ (standard deviation) > 0\n",
      "* Support: z ∈ (0, +∞)\n",
      "* PDF (Probability Density Function): involves exponential and logarithmic functions\n",
      "\n",
      "Detected keywords: Lognormal, Probability Density Function, PDF, μ, σ, scale, standard deviation.\n",
      "\n",
      "The main idea of this content is to define a lognormal distribution with specific parameters. The lognormal distribution is a probability distribution of a random variable whose logarithm is normally distributed. The given parameters μ = 4 and σ > 0 suggest that the distribution has a positive scale and a standard deviation that must be greater than zero. The support of the distribution indicates that it is defined for all positive real numbers. However, the provided PDF formula appears to be incomplete or unclear, making it difficult to fully understand the intended probability density function without further context.\n",
      "The following image appears to be a scanned snippet of text, possibly from a financial or numerical context. \n",
      "\n",
      "### Summary of Extracted Content\n",
      "* The extracted text is numerical: \"70 TO 00\"\n",
      "* No specific names, dates, or keywords are detected\n",
      "* The numbers 70 and 00 are prominent\n",
      "\n",
      "The main idea of this content seems to be a range or limit indicated by the numbers 70 and 00. Without more context, it's unclear what these numbers represent, such as percentages, quantities, or codes. The purpose or meaning of \"70 TO 00\" cannot be determined with certainty from the provided OCR-extracted content alone.\n",
      "The following image appears to contain mathematical constants and symbols. \n",
      "### Mathematical Constants\n",
      "* **Constants and Symbols:**\n",
      "  * jl = Mean\n",
      "  * O = Standard Deviation\n",
      "  * m = 3.14159 (pi)\n",
      "  * e = 2.71828 (Euler's number)\n",
      "* **Detected Keywords:** Mean, Standard Deviation, pi, Euler's number\n",
      "* **Main Idea:** The given content lists mathematical constants and symbols, including the mean, standard deviation, pi (m), and Euler's number (e). These constants are fundamental in various mathematical and statistical calculations. The content seems to be a reference or notation for these important values, possibly for use in a mathematical or scientific context.\n",
      "The following image appears to be a scanned equation or mathematical expression, but the content is unclear and does not provide a coherent message. \n",
      "\n",
      "### Summary of Content\n",
      "* The content is fragmented and unclear\n",
      "* No specific key points or highlights can be identified\n",
      "* No names, dates, numbers, or keywords can be detected with certainty\n",
      "* The main idea or purpose cannot be determined due to the unclear nature of the content\n",
      "\n",
      "The content seems to be a jumbled collection of symbols, letters, and numbers that do not form a recognizable equation or expression. Without more context, it is impossible to provide a meaningful summary or interpretation. If more information or a clearer version of the content is available, a more accurate summary might be possible.\n",
      "The following image appears to be a scanned paragraph discussing statistical concepts. \n",
      "### Statistical Concepts\n",
      "* The formula for calculating the mean is provided as the sum of terms divided by the number of terms.\n",
      "* The formula for probability is given as the number of favorable outcomes divided by the number of possible outcomes, denoted as P(x).\n",
      "Detected keywords: Mean, Probability, P(x), favorable outcomes, possible outcomes.\n",
      "The main idea of this content is to introduce basic statistical concepts, specifically the calculation of the mean and probability. The text provides formulas for these calculations, highlighting the importance of understanding the total number of terms for the mean and the ratio of favorable to possible outcomes for probability. However, the context in which these concepts are being discussed is not clearly provided in the extracted content.\n",
      "The following image appears to contain a fragment of statistical terminology. \n",
      "### Statistical Concept\n",
      "* Estimating sample standard deviation\n",
      "* Mention of 'rma', potentially referring to a specific method or formula\n",
      "Detected keywords: sample standard deviation, rma\n",
      "The main idea of this OCR-extracted content seems to revolve around statistical estimation, specifically focusing on the sample standard deviation and a method or formula referred to as 'rma'. However, without more context, it's unclear what 'rma' stands for or the specifics of how it's used in this estimation process. If 'rma' refers to a specific statistical technique or formula, understanding its application would require additional information or context.\n",
      "No OCR content found to summarize.\n"
     ]
    }
   ],
   "source": [
    "for txt in result['ocr_texts_per_image']:\n",
    "    print(summarize_ocr_text(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5537bdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted metadata in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Fundamental Statistical Concepts\",\n",
      "  \"summary\": \"The document discusses fundamental statistical concepts, including the mean, standard deviation, z-test, and p-value. These measures are crucial in statistics, particularly in fields like science, finance, and engineering. The mean represents the central tendency of a dataset, while the standard deviation measures the variation or dispersion. The z-test determines significant differences between sample and population means, and the p-value quantifies the strength of evidence against the null hypothesis.\n",
      "\n",
      "The text also introduces the 67-95-99 rule, also known as the empirical rule, which describes the distribution of data in a normal (Gaussian) distribution. This rule states that about 68% of data falls within one standard deviation of the mean, 95% within two standard deviations, and 99.7% within three standard deviations.\n",
      "\n",
      "In addition to these concepts, the text explores probability distributions, including the log-normal distribution and the Poisson distribution. The log-normal distribution is a continuous probability distribution where the logarithm of the random variable is normally distributed, making it suitable for modeling data that cannot be negative and often displays a right-skewed pattern. The Poisson distribution is a discrete probability distribution that describes the likelihood of a certain number of events occurring within a fixed interval of time or space.\n",
      "\n",
      "The document provides a comprehensive overview of these statistical concepts, including their applications in various fields such as science, finance, engineering, statistical research, data analysis, quality control, risk analysis, uncertainty, random events, and count data. The text also highlights the importance of understanding these concepts in making predictions and informed decisions.\n",
      "\n",
      "The mean is a fundamental concept in statistics, representing the central tendency of a dataset. The standard deviation measures the variation or dispersion in a dataset, providing valuable insights into the data's distribution. The z-test and p-value are essential in statistical hypothesis testing, determining significant differences between sample and population means and quantifying the strength of evidence against the null hypothesis.\n",
      "\n",
      "The 67-95-99 rule is a useful tool in understanding probabilities and making predictions. The log-normal distribution and Poisson distribution are important probability distributions that have various applications in modeling real-world phenomena. The log-normal distribution is suitable for modeling data that cannot be negative, while the Poisson distribution is ideal for modeling rare or random events.\n",
      "\n",
      "Overall, the document provides a detailed and comprehensive overview of fundamental statistical concepts, their applications, and importance in various fields. It highlights the significance of understanding these concepts in making informed decisions and predictions, and provides a solid foundation for further study and research in statistics and related fields.\",\n",
      "  \"keywords\": \"mean, standard deviation, z-test, p-value, log-normal distribution, Poisson distribution, probability, empirical rule, 67-95-99 rule\",\n",
      "  \"topics\": \"statistics, science, finance, engineering, data analysis, quality control, risk analysis\",\n",
      "  \"author\": \"Not mentioned\",\n",
      "  \"document_type\": \"academic article\"\n",
      "}\n",
      "```\n",
      "\n",
      "Note: The summary field is a detailed and comprehensive overview of the document, covering all important points and concepts. The keywords and topics fields are comma-separated lists of relevant terms and broad subject categories, respectively. The author field indicates that the author is not mentioned in the document. The document_type field specifies that the document is an academic article.\n"
     ]
    }
   ],
   "source": [
    "metadata=generate_metadata(response)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98adc00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
