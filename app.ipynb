{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "196e6c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import tempfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PyPDF2 import PdfReader\n",
    "from docx import Document as DocxDocument\n",
    "import pytesseract\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import io\n",
    "import fitz\n",
    "from docx.opc.constants import RELATIONSHIP_TYPE as RT\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "31897c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "58c6d46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\" # Path set in environment variables for tesseract to work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e34008",
   "metadata": {},
   "source": [
    "### Function to extract full text and all inline images from pdf and docx as txt files wont contain images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "182ddc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_and_inline_images(uploaded_file):\n",
    "    suffix = Path(uploaded_file.name).suffix.lower()\n",
    "    text = \"\"\n",
    "    image_list = []\n",
    "    ocr_texts_per_image = []\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp_file:\n",
    "        tmp_file.write(uploaded_file.read())\n",
    "        tmp_file_path = tmp_file.name\n",
    "\n",
    "    try:\n",
    "        if suffix == \".pdf\":\n",
    "            try:\n",
    "                reader = PdfReader(tmp_file_path)\n",
    "                text = \"\\n\".join([page.extract_text() or \"\" for page in reader.pages])\n",
    "            except Exception:\n",
    "                text = \"\"\n",
    "            pdf_doc = fitz.open(tmp_file_path)\n",
    "            for page in pdf_doc:\n",
    "                images = page.get_images(full=False)\n",
    "                for img in images:\n",
    "                    xref = img[0] if isinstance(img, tuple) else img\n",
    "                    base_image = pdf_doc.extract_image(xref)\n",
    "                    image_data = base_image[\"image\"]\n",
    "                    image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "                    image_list.append(image)\n",
    "                    ocr_img_text = pytesseract.image_to_string(image)\n",
    "                    ocr_texts_per_image.append(ocr_img_text)\n",
    "        elif suffix == \".docx\":\n",
    "            doc = DocxDocument(tmp_file_path)\n",
    "            text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "            rels = doc.part._rels\n",
    "            for rel in rels:\n",
    "                rel = rels[rel]\n",
    "                if rel.reltype == RT.IMAGE:\n",
    "                    image_data = rel.target_part.blob\n",
    "                    image = Image.open(io.BytesIO(image_data)).convert(\"RGB\")\n",
    "                    image_list.append(image)\n",
    "                    ocr_img_text = pytesseract.image_to_string(image)\n",
    "                    ocr_texts_per_image.append(ocr_img_text)\n",
    "        elif suffix == \".txt\":\n",
    "            with open(tmp_file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                text = f.read()\n",
    "        else:\n",
    "            text = f\"Unsupported file type: {suffix}\"\n",
    "    finally:\n",
    "        try:\n",
    "            os.remove(tmp_file_path)\n",
    "        except PermissionError:\n",
    "            pass\n",
    "\n",
    "    return {\n",
    "        \"text\": text.strip(),\n",
    "        \"images\": image_list,\n",
    "        \"ocr_texts_per_image\": ocr_texts_per_image\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724eb9b",
   "metadata": {},
   "source": [
    "### Function to chunk the large text into chunks of size 2800 assuming 1 token is approximately 4 chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "881af969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text_by_tokens(text, max_tokens=700):\n",
    "    chunk_size = 2800\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        current_length += len(word) + 1\n",
    "        if current_length >= chunk_size:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2b757f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)nth_super_ugly_number:\n",
      "  problem:\n",
      "    description: >\n",
      "      Find the nth super ugly number, where a super ugly number is a positive integer \n",
      "      whose prime factors are only from the given list `primes`.\n",
      "\n",
      "    input:\n",
      "      n: The index (1-based) of the super ugly number to return.\n",
      "      primes: A list of prime numbers used to generate super ugly numbers.\n",
      "\n",
      "    output:\n",
      "      dp[n]: The nth super ugly number.\n",
      "\n",
      "  definitions:\n",
      "    dp[i]: >\n",
      "      The i-th super ugly number, where:\n",
      "      - dp[1] is initialized to 1 (the first super ugly number),\n",
      "      - dp[i] is built using previously computed dp values and the prime list.\n",
      "\n",
      "    a[j]: >\n",
      "      The index pointer for each prime number `primes[j]`, initially pointing to dp[1].\n",
      "      - It tracks which multiple of a given prime to consider next.\n",
      "\n",
      "  approach:\n",
      "    type: Dynamic Programming (with multiple moving pointers)\n",
      "    steps:\n",
      "      - Initialize `dp` as a vector of size (n+1), with dp[1] = 1.\n",
      "      - Initialize an index pointer array `a` of size m (number of primes), all set to 1.\n",
      "      - For each i from 2 to n:\n",
      "        - Set val = infinity.\n",
      "        - For each prime:\n",
      "          - Compute `dp[a[j]] * primes[j]`, and keep track of the minimum of all.\n",
      "        - Set dp[i] = min value found.\n",
      "        - For each prime again:\n",
      "          - If the product equals dp[i], increment the respective pointer a[j] to avoid duplicates.\n",
      "\n",
      "  explanation:\n",
      "    - At every step, you are trying to generate the next smallest number \n",
      "      whose prime divisors are limited to the provided list `primes`.\n",
      "    - You generate the next candidates by multiplying previous dp values with each prime.\n",
      "    - The multiple pointers ensure you avoid recomputing duplicate values \n",
      "      and efficiently progress each sequence.\n",
      "    - The result is always increasing, and duplicates are prevented by the condition \n",
      "      `if dp[a[j]] * primes[j] == dp[i]`.\n",
      "\n",
      "  complexity:\n",
      "    time: O(n * k), where k is the number of primes.\n",
      "    space: O(n + k), for storing the dp array and pointer list.\n",
      "\n",
      "  output:\n",
      "    return_value: dp[n]\n",
      "\n",
      "  notes:\n",
      "    - Use of `1LL` ensures multiplication stays in long long to avoid integer overflow.\n",
      "    - Final result is cast to int before returning, since the result fits in 32-bit int.\n",
      "\n",
      "2)ountNumberOfLIS\n",
      "description: >\n",
      "  Computes the number of Longest Increasing Subsequences (LIS) in a given array using Dynamic Programming.\n",
      "  For each element, tracks both the length of the LIS ending there and how many such LIS exist.\n",
      "\n",
      "input:\n",
      "  - n: Number of elements in the array\n",
      "  - a: Array of integers of length n\n",
      "\n",
      "output:\n",
      "  - count: Total number of LIS of maximum length\n",
      "\n",
      "steps:\n",
      "  1. Read Input:\n",
      "    - Read `n` (number of elements)\n",
      "    - Read array `a` of length `n`\n",
      "\n",
      "  2. Initialize Arrays:\n",
      "    - dp[i] = Length of the LIS ending at index i\n",
      "    - c[i] = Number of LIS of length dp[i] ending at index i\n",
      "    - Both initialized to 1, since each element is a LIS of length 1\n",
      "\n",
      "  3. Fill dp and c using nested loops:\n",
      "    for i in 1 to n-1:\n",
      "      for j in 0 to i-1:\n",
      "        if a[j] < a[i]:\n",
      "          if dp[j] + 1 > dp[i]:\n",
      "            dp[i] = dp[j] + 1\n",
      "            c[i] = c[j]        # new longer LIS found, take over count\n",
      "          else if dp[j] + 1 == dp[i]:\n",
      "            c[i] += c[j]       # same-length LIS found, accumulate count\n",
      "\n",
      "    explanation: >\n",
      "      - For each a[i], check all previous elements a[j].\n",
      "      - If a[j] < a[i], a[i] can extend the LIS ending at a[j].\n",
      "      - Update dp[i] to the maximum LIS length, and c[i] to track how many LIS of that length end at i.\n",
      "\n",
      "  4. Find max LIS length:\n",
      "    - ans = max(dp[0 to n-1])\n",
      "\n",
      "  5. Count total number of LIS:\n",
      "    - For all i such that dp[i] == ans:\n",
      "        - Accumulate c[i] into `count`\n",
      "\n",
      "  6. Output:\n",
      "    - Print or return `count` as total number of LIS of maximum length\n",
      "\n",
      "time_complexity: O(n^2)\n",
      "space_complexity: O(n)\n",
      "\n",
      "variables:\n",
      "  - dp: vector<ll> of size n, stores LIS lengths\n",
      "  - c:  vector<ll> of size n, stores LIS counts\n",
      "  - ans: maximum LIS length\n",
      "  - count: total number of LIS of length ans\n",
      "\n",
      "example:\n",
      "  input:\n",
      "    n: 6\n",
      "    a: [1, 3, 5, 4, 7, 2]\n",
      "  dp: [1, 2, 3, 3, 4, 2]\n",
      "  c:  [1, 1, 1, 1, 2, 1]\n",
      "  max_length: 4\n",
      "  result: 2  # Two LIS of length 4: [1,3,4,7] and [1,3,5,7]\n",
      "\n",
      "notes:\n",
      "  - This algorithm only counts LIS, not reconstructs them.\n",
      "  - Can be extended to print all LIS using additional tracking structures.\n",
      "\n",
      "3)problem: Longest Common Subsequence (LCS)\n",
      "   function: longestCommonSubsequence(s, t)\n",
      "   dp_definition:\n",
      "     dp[i][j]: Length of LCS between s[0..i-1] and t[0..j-1]\n",
      "   recurrence:\n",
      "     if s[i-1] == t[j-1]:\n",
      "       dp[i][j] = 1 + dp[i-1][j-1]\n",
      "     else:\n",
      "       dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
      "   base_cases:\n",
      "     - dp[0][j] = 0 for all j (empty s)\n",
      "     - dp[i][0] = 0 for all i (empty t)\n",
      "   result: dp[n][m] (length of LCS between s and t)\n",
      "   time_complexity: O(n * m)\n",
      "   space_complexity: O(n * m)\n",
      "   use_case: Core building block for many string problems.\n",
      "\n",
      "---\n",
      "\n",
      "2. problem: Longest Palindromic Subsequence (LPS)\n",
      "   function: longestPalindromicSubsequence(s)\n",
      "   idea: >\n",
      "     A palindrome reads the same forwards and backwards. So the LPS of s is simply\n",
      "     the LCS of s and its reverse.\n",
      "   steps:\n",
      "     - Let rev = reverse(s)\n",
      "     - Compute LCS(s, rev)\n",
      "   reason: >\n",
      "     Characters that are common in the same order in both s and rev form a palindromic subsequence.\n",
      "   result: Length of the longest palindromic subsequence\n",
      "   example:\n",
      "     s: \"bbabcbcab\"\n",
      "     rev: \"bacbcbabb\"\n",
      "     lps_length: 7 (e.g., \"babcbab\")\n",
      "   time_complexity: O(n^2)\n",
      "\n",
      "---\n",
      "\n",
      "3. problem: Minimum Insertions to Make a String Palindromic\n",
      "   function: minInsertionsToMakePalindrome(s)\n",
      "   idea: >\n",
      "     The minimum number of insertions = s.length() - LPS(s)\n",
      "   reason: >\n",
      "     Once you know the longest palindromic subsequence, all the other characters must be matched by insertions.\n",
      "   formula: min_insertions = len(s) - longestPalindromicSubsequence(s)\n",
      "   example:\n",
      "     s: \"abcd\"\n",
      "     lps: 1 (\"a\", \"b\", \"c\", or \"d\")\n",
      "     result: 3 insertions (e.g., \"dcbabcd\")\n",
      "   time_complexity: O(n^2)\n",
      "\n",
      "---\n",
      "\n",
      "4. problem: Minimum Insertions to Convert s1 to s2\n",
      "   function: minInsertionsToConvert(s1, s2)\n",
      "   idea: >\n",
      "     Use LCS(s1, s2) to determine common part.\n",
      "     The number of insertions required = len(s2) - LCS(s1, s2)\n",
      "   reason: >\n",
      "     To make s1 into s2, insert the characters from s2 that are not in the LCS.\n",
      "   formula: insertions = len(s2) - LCS(s1, s2)\n",
      "   example:\n",
      "     s1: \"abc\"\n",
      "     s2: \"aebdc\"\n",
      "     LCS: \"abc\" → length 3\n",
      "     result: 2 insertions (\"e\" and \"d\")\n",
      "   time_complexity: O(n * m)\n",
      "\n",
      "---\n",
      "\n",
      "shared_base:\n",
      "  core_dp: LCS (Longest Common Subsequence)\n",
      "  recurrence:\n",
      "    if s[i-1] == t[j-1]:\n",
      "      dp[i][j] = 1 + dp[i-1][j-1]\n",
      "    else:\n",
      "      dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
      "  usage: >\n",
      "    All the above problems reuse this LCS DP as their base, either by comparing a string with its reverse\n",
      "    or comparing two different strings to determine how many characters are common or missing.\n",
      "\n",
      "AUTHOR: Samyak Mahapatra\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "with open(\"test.txt\", \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "uploaded_file = io.BytesIO(file_bytes)\n",
    "uploaded_file.name = \"test.txt\" \n",
    "\n",
    "result = extract_text_and_inline_images(uploaded_file)\n",
    "\n",
    "print(result['text'])\n",
    "print(result['images'])\n",
    "print(result['ocr_texts_per_image'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d3b153a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)nth_super_ugly_number: problem: description: > Find the nth super ugly number, where a super ugly number is a positive integer whose prime factors are only from the given list `primes`. input: n: The index (1-based) of the super ugly number to return. primes: A list of prime numbers used to generate super ugly numbers. output: dp[n]: The nth super ugly number. definitions: dp[i]: > The i-th super ugly number, where: - dp[1] is initialized to 1 (the first super ugly number), - dp[i] is built using previously computed dp values and the prime list. a[j]: > The index pointer for each prime number `primes[j]`, initially pointing to dp[1]. - It tracks which multiple of a given prime to consider next. approach: type: Dynamic Programming (with multiple moving pointers) steps: - Initialize `dp` as a vector of size (n+1), with dp[1] = 1. - Initialize an index pointer array `a` of size m (number of primes), all set to 1. - For each i from 2 to n: - Set val = infinity. - For each prime: - Compute `dp[a[j]] * primes[j]`, and keep track of the minimum of all. - Set dp[i] = min value found. - For each prime again: - If the product equals dp[i], increment the respective pointer a[j] to avoid duplicates. explanation: - At every step, you are trying to generate the next smallest number whose prime divisors are limited to the provided list `primes`. - You generate the next candidates by multiplying previous dp values with each prime. - The multiple pointers ensure you avoid recomputing duplicate values and efficiently progress each sequence. - The result is always increasing, and duplicates are prevented by the condition `if dp[a[j]] * primes[j] == dp[i]`. complexity: time: O(n * k), where k is the number of primes. space: O(n + k), for storing the dp array and pointer list. output: return_value: dp[n] notes: - Use of `1LL` ensures multiplication stays in long long to avoid integer overflow. - Final result is cast to int before returning, since the result fits in 32-bit int. 2)ountNumberOfLIS description: > Computes the number of Longest Increasing Subsequences (LIS) in a given array using Dynamic Programming. For each element, tracks both the length of the LIS ending there and how many such LIS exist. input: - n: Number of elements in the array - a: Array of integers of length n output: - count: Total number of LIS of maximum length steps: 1. Read Input: - Read `n` (number of elements) - Read array `a` of length `n` 2. Initialize Arrays: - dp[i] = Length of the LIS ending at index i - c[i] = Number of LIS of length dp[i] ending at index i - Both initialized to 1, since each element is a LIS of length 1 3. Fill dp and c using nested loops: for i in 1 to n-1: for j in 0 to i-1: if a[j] < a[i]: if dp[j] + 1 > dp[i]: dp[i] = dp[j] + 1 c[i] = c[j] # new longer LIS found, 2800\n",
      "take over count else if dp[j] + 1 == dp[i]: c[i] += c[j] # same-length LIS found, accumulate count explanation: > - For each a[i], check all previous elements a[j]. - If a[j] < a[i], a[i] can extend the LIS ending at a[j]. - Update dp[i] to the maximum LIS length, and c[i] to track how many LIS of that length end at i. 4. Find max LIS length: - ans = max(dp[0 to n-1]) 5. Count total number of LIS: - For all i such that dp[i] == ans: - Accumulate c[i] into `count` 6. Output: - Print or return `count` as total number of LIS of maximum length time_complexity: O(n^2) space_complexity: O(n) variables: - dp: vector<ll> of size n, stores LIS lengths - c: vector<ll> of size n, stores LIS counts - ans: maximum LIS length - count: total number of LIS of length ans example: input: n: 6 a: [1, 3, 5, 4, 7, 2] dp: [1, 2, 3, 3, 4, 2] c: [1, 1, 1, 1, 2, 1] max_length: 4 result: 2 # Two LIS of length 4: [1,3,4,7] and [1,3,5,7] notes: - This algorithm only counts LIS, not reconstructs them. - Can be extended to print all LIS using additional tracking structures. 3)problem: Longest Common Subsequence (LCS) function: longestCommonSubsequence(s, t) dp_definition: dp[i][j]: Length of LCS between s[0..i-1] and t[0..j-1] recurrence: if s[i-1] == t[j-1]: dp[i][j] = 1 + dp[i-1][j-1] else: dp[i][j] = max(dp[i-1][j], dp[i][j-1]) base_cases: - dp[0][j] = 0 for all j (empty s) - dp[i][0] = 0 for all i (empty t) result: dp[n][m] (length of LCS between s and t) time_complexity: O(n * m) space_complexity: O(n * m) use_case: Core building block for many string problems. --- 2. problem: Longest Palindromic Subsequence (LPS) function: longestPalindromicSubsequence(s) idea: > A palindrome reads the same forwards and backwards. So the LPS of s is simply the LCS of s and its reverse. steps: - Let rev = reverse(s) - Compute LCS(s, rev) reason: > Characters that are common in the same order in both s and rev form a palindromic subsequence. result: Length of the longest palindromic subsequence example: s: \"bbabcbcab\" rev: \"bacbcbabb\" lps_length: 7 (e.g., \"babcbab\") time_complexity: O(n^2) --- 3. problem: Minimum Insertions to Make a String Palindromic function: minInsertionsToMakePalindrome(s) idea: > The minimum number of insertions = s.length() - LPS(s) reason: > Once you know the longest palindromic subsequence, all the other characters must be matched by insertions. formula: min_insertions = len(s) - longestPalindromicSubsequence(s) example: s: \"abcd\" lps: 1 (\"a\", \"b\", \"c\", or \"d\") result: 3 insertions (e.g., \"dcbabcd\") time_complexity: O(n^2) --- 4. problem: Minimum Insertions to Convert s1 to s2 function: minInsertionsToConvert(s1, s2) idea: > Use LCS(s1, s2) to determine common part. The number of insertions required = len(s2) - LCS(s1, s2) reason: > To make s1 into s2, insert the characters 2807\n",
      "from s2 that are not in the LCS. formula: insertions = len(s2) - LCS(s1, s2) example: s1: \"abc\" s2: \"aebdc\" LCS: \"abc\" → length 3 result: 2 insertions (\"e\" and \"d\") time_complexity: O(n * m) --- shared_base: core_dp: LCS (Longest Common Subsequence) recurrence: if s[i-1] == t[j-1]: dp[i][j] = 1 + dp[i-1][j-1] else: dp[i][j] = max(dp[i-1][j], dp[i][j-1]) usage: > All the above problems reuse this LCS DP as their base, either by comparing a string with its reverse or comparing two different strings to determine how many characters are common or missing. AUTHOR: Samyak Mahapatra 582\n"
     ]
    }
   ],
   "source": [
    "chunks=chunk_text_by_tokens(result['text'])\n",
    "for chunk in chunks:\n",
    "    print(chunk,len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86c954",
   "metadata": {},
   "source": [
    "### Summarising with Groq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "749c97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_with_groq(text, api_key, model=\"llama-3.3-70b-versatile\", max_tokens=700):\n",
    "    llm = ChatGroq(model=model, api_key=api_key, max_tokens=max_tokens)\n",
    "    prompt = f\"Summarize the following text in detail,extract the meaningful sections of document like author names,important keywords etc, but keep the summary under {max_tokens} tokens:\\n\\n{text}\"\n",
    "    response = llm([\n",
    "        SystemMessage(content=\"You are a professional summarization assistant.\"),\n",
    "        HumanMessage(content=prompt)\n",
    "    ])\n",
    "    return response.content.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f931c9c0",
   "metadata": {},
   "source": [
    "Hierarchical summarization is a technique designed to handle very large documents that exceed the token limits of language models like Groq’s Llama 3.3 70B Versatile. First, the document is divided into manageable chunks, and each chunk is individually summarized. Then, all these chunk summaries are combined and, if necessary, summarized again to produce a concise final summary within the model’s token limit. This approach ensures that important information from the entire document is retained and condensed efficiently, making it possible to generate high-quality summaries even for massive documents that would otherwise overwhelm the model’s input size. The main advantages are scalability, comprehensive coverage, and improved summary quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dd00eb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_pdf_text(full_text):\n",
    "    chunks = chunk_text_by_tokens(full_text, max_tokens=700)\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        summary = summarize_with_groq(chunk, api_key=GROQ_API_KEY, model=\"llama-3.3-70b-versatile\", max_tokens=700)\n",
    "        summaries.append(summary)\n",
    "    combined_summary = \"\\n\".join(summaries)\n",
    "    if len(summaries) > 1 or len(combined_summary.split()) > 700:\n",
    "        combined_summary = summarize_with_groq(combined_summary, api_key=GROQ_API_KEY, model=\"llama-3.3-70b-versatile\", max_tokens=700)\n",
    "    return combined_summary.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4748010a",
   "metadata": {},
   "source": [
    "### Function to generate Metadata using the summarised text by groq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2a32eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metadata(summarized_text):\n",
    "    llm = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key=GROQ_API_KEY, max_tokens=700)\n",
    "    prompt = f\"\"\"\n",
    "You are a professional and wonderful metadata assistant.\n",
    "\n",
    "Analyze the following document summary and return structured metadata in JSON format with fields: \n",
    "- title\n",
    "- summary (at least 15-20 lines in detail covering all important points)\n",
    "- keywords (comma-separated)\n",
    "- topics (broad subject categories)\n",
    "- author (if mentioned)\n",
    "- document_type\n",
    "Extract and leverage the important sections of summary\n",
    "Document Summary:\n",
    "{summarized_text}\n",
    "\"\"\"\n",
    "    try:\n",
    "        response = llm([\n",
    "            SystemMessage(content=\"You are a metadata extraction assistant.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        st.error(f\"Metadata extraction failed: {e}\")\n",
    "        return '{\"error\": \"Metadata extraction failed.\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1692ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_ocr_text(ocr_text):\n",
    "    if not ocr_text.strip():\n",
    "        return \"No OCR content found to summarize.\"\n",
    "    llm = ChatGroq(model=\"llama-3.3-70b-versatile\", api_key=GROQ_API_KEY)\n",
    "    prompt = (\n",
    "        \"You are a professional assistant. \"\n",
    "        \"Start your response with 'The following image ...'. \"\n",
    "        \"Summarize the following OCR-extracted content in a clear, well-organized, and visually appealing markdown format. \"\n",
    "        \"Your summary should include:\\n\"\n",
    "        \"- A short title or heading for the content\\n\"\n",
    "        \"- Key points or highlights as a bullet list\\n\"\n",
    "        \"- Detected names, dates, numbers, or keywords (if any)\\n\"\n",
    "        \"- A concise paragraph summarizing the main idea or purpose\\n\"\n",
    "        \"If the content is a graph or chart, explain axes and key trends. \"\n",
    "        \"If it's a table, highlight main comparisons or figures. \"\n",
    "        \"If it's a scanned paragraph, summarize the main idea. \"\n",
    "        \"Avoid assumptions. If content is unclear, mention it.\\n\\n\"\n",
    "        f\"OCR Text:\\n{ocr_text}\"\n",
    "    )\n",
    "    try:\n",
    "        response = llm([\n",
    "            SystemMessage(content=\"You summarize OCR-extracted content in structured markdown.\"),\n",
    "            HumanMessage(content=prompt)\n",
    "        ])\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"OCR summarization failed: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2139281",
   "metadata": {},
   "source": [
    "### Testing each fuctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3e8796",
   "metadata": {},
   "source": [
    "### 1)TXT File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "47c39f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1)nth_super_ugly_number:\n",
      "  problem:\n",
      "    description: >\n",
      "      Find the nth super ugly number, where a super ugly number is a positive integer \n",
      "      whose prime factors are only from the given list `primes`.\n",
      "\n",
      "    input:\n",
      "      n: The index (1-based) of the super ugly number to return.\n",
      "      primes: A list of prime numbers used to generate super ugly numbers.\n",
      "\n",
      "    output:\n",
      "      dp[n]: The nth super ugly number.\n",
      "\n",
      "  definitions:\n",
      "    dp[i]: >\n",
      "      The i-th super ugly number, where:\n",
      "      - dp[1] is initialized to 1 (the first super ugly number),\n",
      "      - dp[i] is built using previously computed dp values and the prime list.\n",
      "\n",
      "    a[j]: >\n",
      "      The index pointer for each prime number `primes[j]`, initially pointing to dp[1].\n",
      "      - It tracks which multiple of a given prime to consider next.\n",
      "\n",
      "  approach:\n",
      "    type: Dynamic Programming (with multiple moving pointers)\n",
      "    steps:\n",
      "      - Initialize `dp` as a vector of size (n+1), with dp[1] = 1.\n",
      "      - Initialize an index pointer array `a` of size m (number of primes), all set to 1.\n",
      "      - For each i from 2 to n:\n",
      "        - Set val = infinity.\n",
      "        - For each prime:\n",
      "          - Compute `dp[a[j]] * primes[j]`, and keep track of the minimum of all.\n",
      "        - Set dp[i] = min value found.\n",
      "        - For each prime again:\n",
      "          - If the product equals dp[i], increment the respective pointer a[j] to avoid duplicates.\n",
      "\n",
      "  explanation:\n",
      "    - At every step, you are trying to generate the next smallest number \n",
      "      whose prime divisors are limited to the provided list `primes`.\n",
      "    - You generate the next candidates by multiplying previous dp values with each prime.\n",
      "    - The multiple pointers ensure you avoid recomputing duplicate values \n",
      "      and efficiently progress each sequence.\n",
      "    - The result is always increasing, and duplicates are prevented by the condition \n",
      "      `if dp[a[j]] * primes[j] == dp[i]`.\n",
      "\n",
      "  complexity:\n",
      "    time: O(n * k), where k is the number of primes.\n",
      "    space: O(n + k), for storing the dp array and pointer list.\n",
      "\n",
      "  output:\n",
      "    return_value: dp[n]\n",
      "\n",
      "  notes:\n",
      "    - Use of `1LL` ensures multiplication stays in long long to avoid integer overflow.\n",
      "    - Final result is cast to int before returning, since the result fits in 32-bit int.\n",
      "\n",
      "2)ountNumberOfLIS\n",
      "description: >\n",
      "  Computes the number of Longest Increasing Subsequences (LIS) in a given array using Dynamic Programming.\n",
      "  For each element, tracks both the length of the LIS ending there and how many such LIS exist.\n",
      "\n",
      "input:\n",
      "  - n: Number of elements in the array\n",
      "  - a: Array of integers of length n\n",
      "\n",
      "output:\n",
      "  - count: Total number of LIS of maximum length\n",
      "\n",
      "steps:\n",
      "  1. Read Input:\n",
      "    - Read `n` (number of elements)\n",
      "    - Read array `a` of length `n`\n",
      "\n",
      "  2. Initialize Arrays:\n",
      "    - dp[i] = Length of the LIS ending at index i\n",
      "    - c[i] = Number of LIS of length dp[i] ending at index i\n",
      "    - Both initialized to 1, since each element is a LIS of length 1\n",
      "\n",
      "  3. Fill dp and c using nested loops:\n",
      "    for i in 1 to n-1:\n",
      "      for j in 0 to i-1:\n",
      "        if a[j] < a[i]:\n",
      "          if dp[j] + 1 > dp[i]:\n",
      "            dp[i] = dp[j] + 1\n",
      "            c[i] = c[j]        # new longer LIS found, take over count\n",
      "          else if dp[j] + 1 == dp[i]:\n",
      "            c[i] += c[j]       # same-length LIS found, accumulate count\n",
      "\n",
      "    explanation: >\n",
      "      - For each a[i], check all previous elements a[j].\n",
      "      - If a[j] < a[i], a[i] can extend the LIS ending at a[j].\n",
      "      - Update dp[i] to the maximum LIS length, and c[i] to track how many LIS of that length end at i.\n",
      "\n",
      "  4. Find max LIS length:\n",
      "    - ans = max(dp[0 to n-1])\n",
      "\n",
      "  5. Count total number of LIS:\n",
      "    - For all i such that dp[i] == ans:\n",
      "        - Accumulate c[i] into `count`\n",
      "\n",
      "  6. Output:\n",
      "    - Print or return `count` as total number of LIS of maximum length\n",
      "\n",
      "time_complexity: O(n^2)\n",
      "space_complexity: O(n)\n",
      "\n",
      "variables:\n",
      "  - dp: vector<ll> of size n, stores LIS lengths\n",
      "  - c:  vector<ll> of size n, stores LIS counts\n",
      "  - ans: maximum LIS length\n",
      "  - count: total number of LIS of length ans\n",
      "\n",
      "example:\n",
      "  input:\n",
      "    n: 6\n",
      "    a: [1, 3, 5, 4, 7, 2]\n",
      "  dp: [1, 2, 3, 3, 4, 2]\n",
      "  c:  [1, 1, 1, 1, 2, 1]\n",
      "  max_length: 4\n",
      "  result: 2  # Two LIS of length 4: [1,3,4,7] and [1,3,5,7]\n",
      "\n",
      "notes:\n",
      "  - This algorithm only counts LIS, not reconstructs them.\n",
      "  - Can be extended to print all LIS using additional tracking structures.\n",
      "\n",
      "3)problem: Longest Common Subsequence (LCS)\n",
      "   function: longestCommonSubsequence(s, t)\n",
      "   dp_definition:\n",
      "     dp[i][j]: Length of LCS between s[0..i-1] and t[0..j-1]\n",
      "   recurrence:\n",
      "     if s[i-1] == t[j-1]:\n",
      "       dp[i][j] = 1 + dp[i-1][j-1]\n",
      "     else:\n",
      "       dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
      "   base_cases:\n",
      "     - dp[0][j] = 0 for all j (empty s)\n",
      "     - dp[i][0] = 0 for all i (empty t)\n",
      "   result: dp[n][m] (length of LCS between s and t)\n",
      "   time_complexity: O(n * m)\n",
      "   space_complexity: O(n * m)\n",
      "   use_case: Core building block for many string problems.\n",
      "\n",
      "---\n",
      "\n",
      "2. problem: Longest Palindromic Subsequence (LPS)\n",
      "   function: longestPalindromicSubsequence(s)\n",
      "   idea: >\n",
      "     A palindrome reads the same forwards and backwards. So the LPS of s is simply\n",
      "     the LCS of s and its reverse.\n",
      "   steps:\n",
      "     - Let rev = reverse(s)\n",
      "     - Compute LCS(s, rev)\n",
      "   reason: >\n",
      "     Characters that are common in the same order in both s and rev form a palindromic subsequence.\n",
      "   result: Length of the longest palindromic subsequence\n",
      "   example:\n",
      "     s: \"bbabcbcab\"\n",
      "     rev: \"bacbcbabb\"\n",
      "     lps_length: 7 (e.g., \"babcbab\")\n",
      "   time_complexity: O(n^2)\n",
      "\n",
      "---\n",
      "\n",
      "3. problem: Minimum Insertions to Make a String Palindromic\n",
      "   function: minInsertionsToMakePalindrome(s)\n",
      "   idea: >\n",
      "     The minimum number of insertions = s.length() - LPS(s)\n",
      "   reason: >\n",
      "     Once you know the longest palindromic subsequence, all the other characters must be matched by insertions.\n",
      "   formula: min_insertions = len(s) - longestPalindromicSubsequence(s)\n",
      "   example:\n",
      "     s: \"abcd\"\n",
      "     lps: 1 (\"a\", \"b\", \"c\", or \"d\")\n",
      "     result: 3 insertions (e.g., \"dcbabcd\")\n",
      "   time_complexity: O(n^2)\n",
      "\n",
      "---\n",
      "\n",
      "4. problem: Minimum Insertions to Convert s1 to s2\n",
      "   function: minInsertionsToConvert(s1, s2)\n",
      "   idea: >\n",
      "     Use LCS(s1, s2) to determine common part.\n",
      "     The number of insertions required = len(s2) - LCS(s1, s2)\n",
      "   reason: >\n",
      "     To make s1 into s2, insert the characters from s2 that are not in the LCS.\n",
      "   formula: insertions = len(s2) - LCS(s1, s2)\n",
      "   example:\n",
      "     s1: \"abc\"\n",
      "     s2: \"aebdc\"\n",
      "     LCS: \"abc\" → length 3\n",
      "     result: 2 insertions (\"e\" and \"d\")\n",
      "   time_complexity: O(n * m)\n",
      "\n",
      "---\n",
      "\n",
      "shared_base:\n",
      "  core_dp: LCS (Longest Common Subsequence)\n",
      "  recurrence:\n",
      "    if s[i-1] == t[j-1]:\n",
      "      dp[i][j] = 1 + dp[i-1][j-1]\n",
      "    else:\n",
      "      dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
      "  usage: >\n",
      "    All the above problems reuse this LCS DP as their base, either by comparing a string with its reverse\n",
      "    or comparing two different strings to determine how many characters are common or missing.\n",
      "\n",
      "AUTHOR: Samyak Mahapatra\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "with open(\"test.txt\", \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "uploaded_file = io.BytesIO(file_bytes)\n",
    "uploaded_file.name = \"test.txt\" \n",
    "\n",
    "result = extract_text_and_inline_images(uploaded_file)\n",
    "\n",
    "print(result['text'])\n",
    "print(result['images'])\n",
    "print(result['ocr_texts_per_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0e5d004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary of the Document:**\n",
      "\n",
      "The document discusses various problems related to dynamic programming, including finding the nth super ugly number, counting the number of Longest Increasing Subsequences (LIS) in an array, and determining the number of insertions required to make a string palindromic. The problems are solved using dynamic programming techniques, with a focus on time and space complexity analysis.\n",
      "\n",
      "**Extracted Information:**\n",
      "\n",
      "* **Author Names:** \n",
      "  + Not mentioned in most sections\n",
      "  + Samyak Mahapatra (mentioned in one section)\n",
      "* **Important Keywords:** \n",
      "  + Dynamic Programming\n",
      "  + Prime Factors\n",
      "  + Super Ugly Number\n",
      "  + Longest Increasing Subsequences\n",
      "  + Array\n",
      "  + Longest Common Subsequence (LCS)\n",
      "  + Longest Palindromic Subsequence (LPS)\n",
      "  + Minimum Insertions to Make a String Palindromic\n",
      "* **Problem Statements:**\n",
      "  + Finding the nth super ugly number\n",
      "  + Counting the number of Longest Increasing Subsequences (LIS) in an array\n",
      "  + Determining the number of insertions required to make a string palindromic\n",
      "  + Finding the Longest Common Subsequence (LCS) between two strings\n",
      "  + Finding the Longest Palindromic Subsequence (LPS) in a string\n",
      "* **Algorithms:**\n",
      "  + Dynamic programming with multiple moving pointers for finding the nth super ugly number\n",
      "  + Dynamic programming for counting the number of Longest Increasing Subsequences (LIS) in an array\n",
      "  + Dynamic programming for determining the number of insertions required to make a string palindromic\n",
      "  + Dynamic programming for finding the Longest Common Subsequence (LCS) between two strings\n",
      "  + Dynamic programming for finding the Longest Palindromic Subsequence (LPS) in a string\n",
      "* **Time Complexities:**\n",
      "  + O(n * k) for finding the nth super ugly number\n",
      "  + O(n^2) for counting the number of Longest Increasing Subsequences (LIS) in an array\n",
      "  + O(n * m) for determining the number of insertions required to make a string palindromic\n",
      "  + O(n * m) for finding the Longest Common Subsequence (LCS) between two strings\n",
      "  + O(n^2) for finding the Longest Palindromic Subsequence (LPS) in a string\n",
      "* **Space Complexities:**\n",
      "  + O(n + k) for finding the nth super ugly number\n",
      "  + O(n) for counting the number of Longest Increasing Subsequences (LIS) in an array\n",
      "  + O(n * m) for determining the number of insertions required to make a string palindromic\n",
      "  + O(n * m) for finding the Longest Common Subsequence (LCS) between two strings\n",
      "  + O(n^2) for finding the Longest Palindromic Subsequence (LPS) in a string\n",
      "\n",
      "**Key Sections:**\n",
      "\n",
      "1. **LCS Formula:** The formula for calculating the LCS is provided as a recurrence relation.\n",
      "2. **Insertions Calculation:** The formula for calculating insertions is provided as `insertions = len(s2) - LCS(s1, s2)`.\n",
      "3. **Time Complexity:** The time complexity of the approach is O(n * m), where\n"
     ]
    }
   ],
   "source": [
    "response=summarize_pdf_text(result['text'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d47489e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted metadata in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Dynamic Programming Techniques for Solving Complex Problems\",\n",
      "  \"summary\": \"The document discusses various problems related to dynamic programming, including finding the nth super ugly number, counting the number of Longest Increasing Subsequences (LIS) in an array, and determining the number of insertions required to make a string palindromic. The problems are solved using dynamic programming techniques, with a focus on time and space complexity analysis. The document covers various algorithms, including dynamic programming with multiple moving pointers, and provides formulas for calculating the Longest Common Subsequence (LCS) and the number of insertions required to make a string palindromic. The time complexities for the approaches are provided, including O(n * k) for finding the nth super ugly number, O(n^2) for counting the number of Longest Increasing Subsequences (LIS) in an array, and O(n * m) for determining the number of insertions required to make a string palindromic. The space complexities are also provided, including O(n + k) for finding the nth super ugly number, O(n) for counting the number of Longest Increasing Subsequences (LIS) in an array, and O(n * m) for determining the number of insertions required to make a string palindromic. The document also covers the Longest Palindromic Subsequence (LPS) problem and provides a formula for calculating the LCS. The key sections of the document include the LCS formula, insertions calculation, and time complexity analysis. Overall, the document provides a comprehensive overview of dynamic programming techniques for solving complex problems, including those related to strings, arrays, and sequences. The document is useful for researchers and practitioners interested in dynamic programming and its applications. The techniques and algorithms presented in the document can be used to solve a wide range of problems, including those related to bioinformatics, data compression, and algorithm design. The document also provides a detailed analysis of the time and space complexities of the approaches, making it a valuable resource for those interested in optimizing their algorithms. In addition to the technical details, the document also provides a clear and concise explanation of the problems and solutions, making it accessible to a wide range of readers. The document is well-organized and easy to follow, with clear headings and sections that make it easy to navigate. The use of formulas and algorithms is also well-explained, making it easy for readers to understand and implement the techniques presented in the document.\",\n",
      "  \"keywords\": \"Dynamic Programming, Prime Factors, Super Ugly Number, Longest Increasing Subsequences, Array, Longest Common Subsequence, Longest Palindromic Subsequence, Minimum Insertions to Make a String Palindromic\",\n",
      "  \"topics\": \"Algorithms, Dynamic Programming, Computer Science, Data Structures\",\n",
      "  \"author\": \"Samyak Mahapatra\",\n",
      "  \"document_type\": \"Technical Report\"\n",
      "}\n",
      "```\n",
      "\n",
      "Note: The summary field is at least 15-20 lines in detail, covering all important points from the document summary.\n"
     ]
    }
   ],
   "source": [
    "metadata=generate_metadata(response)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415e117",
   "metadata": {},
   "source": [
    "### 2)PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fa23ffad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tiger ( Panthera tigris ) is the largest member of the cat family and one of the world ’s most iconic \n",
      "and powerful predators. Easily recognized by its striking orange coat with black stripes, the tiger is \n",
      "native to various parts of Asia, inhabiting forests, grasslands, and mangrove swamps. Tigers are \n",
      "solitary and territorial animals, relying on stealth and strength to hunt prey such as deer, wild boar, \n",
      "and buffalo. Sadly, their populations have declined sharply due to habitat loss, poaching, and huma n-\n",
      "wildlife conflict, leaving fewer than 4,000 tigers in the wild today. As an endangered species and a \n",
      "keystone predator, the tiger plays a crucial role in maintaining the health of its ecosystem. Revered in \n",
      "many cultures as a symbol of strength and courag e, the tiger ’s survival depends on ongoing \n",
      "conservation efforts to protect both the species and its natural habitats.  \n",
      " \n",
      "The elephant is the largest living land animal, easily recognized by its massive body, long trunk, large \n",
      "ears, and ivory tusks.  Three sp ecies exist today: the African bush elephant, the African forest \n",
      "elephant, and the Asian elephant, each adapted to a range of habitats across Africa and Asia, \n",
      "including savannas, forests, and grasslands.  Elephants are highly intelligent, social creatures k nown \n",
      "for their strong family bonds and remarkable memories.  Female elephants, or cows, live in \n",
      "matriarchal herds with their young, while adult males are more solitary or form loose bachelor \n",
      "groups.  Their trunks serve many purposes, from picking up food and  water to communicating and \n",
      "expressing emotions.  Elephants are herbivores, feeding on grasses, leaves, fruits, and bark, and they \n",
      "play a crucial role as keystone species by shaping their ecosystems.  Sadly, elephant populations have \n",
      "declined due to habitat loss, poaching for ivory, and human -wildlife conflict, making their \n",
      "conservation a global priority.  Despite their size and strength, elephants are vulnerable and need \n",
      "protection to ensure their survival for future generations  \n",
      " \n",
      "The parrot is a vibrant and i ntelligent bird known for its strikingly colorful feathers, strong curved \n",
      "beak, and remarkable ability to mimic sounds, including human speech. Found mainly in tropical and \n",
      "subtropical regions, parrots thrive in a variety of habitats such as rainforests, w oodlands, and \n",
      "savannas. They are social creatures, often living in flocks and forming close bonds with their mates. \n",
      "\n",
      "Parrots use their zygodactyl feet —two toes facing forward and two backward —to skillfully grasp food \n",
      "and climb. Their diet typically consists  of seeds, fruits, nuts, and sometimes insects. Highly playful \n",
      "and curious, parrots are celebrated for their problem -solving skills and affectionate nature, making \n",
      "them popular pets. However, many parrot species face threats from habitat loss and the illeg al pet \n",
      "trade, leading to declining populations and highlighting the need for conservation efforts to protect \n",
      "these extraordinary birds.  \n",
      " \n",
      " \n",
      "The dog is a domesticated mammal known for its intelligence, loyalty, and companionship, making it \n",
      "one of humanity ’s oldest and most beloved animal partners. Dogs come in a vast variety of breeds, \n",
      "each with its own unique physical traits and behavioral tendencies, shaped by generations of \n",
      "selective breeding for specific tasks such as herding, hunting, guarding, or compan ionship. While \n",
      "breed can influence a dog ’s energy level, trainability, and temperament —for example, herding \n",
      "breeds are often energetic and attentive, while hounds may be more independent —every dog is also \n",
      "an individual with its own personality. Dogs are hi ghly social animals, forming strong bonds with \n",
      "humans and other animals, and they communicate through a combination of vocalizations, body \n",
      "language, and facial expressions. Their adaptability and eagerness to please have made them \n",
      "invaluable as working ani mals and cherished as pets in homes around the world. While genetics play \n",
      "a role in their behavior, a dog ’s upbringing, environment, and training are equally important in \n",
      "shaping its character and temperamen  \n",
      " \n",
      "AUTHOR: SAMYAK MAHAPATRA\n",
      "['Best.\\nSummer.\\nEver.\\n', 'It was the best of\\ntimes, it was the worst\\nof times, it was the age\\nof wisdom, it was the\\nage of foolishness...\\n', \"[choose you, And Fl choose\\n‘you over and over. Without\\n\\npause, without a doubt,\\nina heartbeat. I'll keep\\nchoosing you.\\n\\n\"]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "with open(\"test.pdf\", \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "uploaded_file = io.BytesIO(file_bytes)\n",
    "uploaded_file.name = \"test.pdf\" \n",
    "\n",
    "result = extract_text_and_inline_images(uploaded_file)\n",
    "\n",
    "print(result['text'])\n",
    "# print(result['images'])\n",
    "print(result['ocr_texts_per_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "bc83f11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Detailed Summary:**\n",
      "\n",
      "The provided text discusses two separate topics: the first part focuses on three iconic species (tiger, elephant, and parrot), while the second part talks about dogs and conservation efforts for extraordinary birds. \n",
      "\n",
      "The first part describes the tiger, a powerful predator native to Asia, recognized by its distinctive orange coat with black stripes. Unfortunately, tiger populations have declined due to habitat loss, poaching, and human-wildlife conflict. The elephant, the largest living land animal, is highly intelligent and social, with three species existing today. Elephants are herbivores and play a crucial role in shaping their ecosystems, but their populations are declining due to similar threats. The parrot, a vibrant and intelligent bird, is known for its colorful feathers and ability to mimic sounds, but many species face threats from habitat loss and human activities.\n",
      "\n",
      "In the second part, the text shifts to discussing dogs, highlighting their intelligence, loyalty, and companionship. Dogs come in various breeds, each with distinct physical traits and behavioral tendencies shaped by selective breeding. Despite breed influences on energy level, trainability, and temperament, every dog is an individual with its own personality. The text also mentions the importance of conservation efforts for extraordinary birds affected by loss and the illegal pet trade.\n",
      "\n",
      "**Extracted Information:**\n",
      "\n",
      "* **Author Names:** \n",
      "  + None mentioned (first part)\n",
      "  + Samyak Mahapatra (second part)\n",
      "* **Important Keywords:**\n",
      "  + Tiger\n",
      "  + Elephant\n",
      "  + Parrot\n",
      "  + Habitat loss\n",
      "  + Poaching\n",
      "  + Human-wildlife conflict\n",
      "  + Conservation\n",
      "  + Keystone species\n",
      "  + Ecosystems\n",
      "  + Endangered species\n",
      "  + Intelligence\n",
      "  + Social behavior\n",
      "  + Adaptation\n",
      "  + Biodiversity\n",
      "  + Dogs\n",
      "  + Breeds\n",
      "  + Loyalty\n",
      "  + Companionship\n",
      "  + Social animals\n",
      "  + Trainability\n",
      "  + Temperament\n",
      "* **Species Mentioned:**\n",
      "  + Tiger (Panthera tigris)\n",
      "  + African bush elephant\n",
      "  + African forest elephant\n",
      "  + Asian elephant\n",
      "  + Parrot (various species)\n",
      "  + Dogs (various breeds)\n",
      "* **Habitats Mentioned:**\n",
      "  + Forests\n",
      "  + Grasslands\n",
      "  + Mangrove swamps\n",
      "  + Savannas\n",
      "  + Rainforests\n",
      "  + Woodlands\n",
      "* **Conservation Status:**\n",
      "  + Tiger: Endangered\n",
      "  + Elephant: Vulnerable\n",
      "  + Parrot: Many species threatened by habitat loss and human activities\n",
      "  + Dogs: Not applicable\n",
      "  + Extraordinary birds: Affected by loss and the illegal pet trade\n"
     ]
    }
   ],
   "source": [
    "response=summarize_pdf_text(result['text'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "588b2660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following image contains a short and concise OCR-extracted content. \n",
      "### Summer Message\n",
      "* The content consists of three short words \n",
      "Key points: \n",
      "- Best\n",
      "- Summer\n",
      "- Ever\n",
      "Detected keywords: Summer.\n",
      "The main idea of this content appears to be a brief expression of enthusiasm or excitement about the summer season, with the words \"Best. Summer. Ever.\" likely indicating a positive anticipation or experience. However, without more context, the purpose or origin of this message is unclear.\n",
      "The following image appears to be a scanned paragraph of text. \n",
      "### Introduction to a Historical Narrative\n",
      "* Contrasting periods in time\n",
      "* Coexistence of wisdom and foolishness\n",
      "* Historical context not explicitly stated\n",
      "Detected keywords: wisdom, foolishness, best of times, worst of times. \n",
      "The main idea of this paragraph, which seems to be the opening of a historical narrative, possibly from the novel \"A Tale of Two Cities\" by Charles Dickens, is to set a tone that highlights the contradictions and complexities of the era being described. The text juxtaposes positive and negative aspects of the time, indicating a deeper exploration of societal dynamics.\n",
      "The following image appears to be a scanned paragraph of a romantic text. \n",
      "### Romantic Declaration\n",
      "* The speaker expresses their commitment to choosing the person they love\n",
      "* The choice is made without hesitation or doubt\n",
      "* The decision is repeated \"over and over\"\n",
      "Detected keywords: love, choice, commitment\n",
      "The main idea of this text is a romantic declaration where the speaker affirmatively chooses their loved one repeatedly and without any doubt, emphasizing the depth of their commitment and love. The tone is one of certainty and devotion, highlighting the importance of the relationship to the speaker.\n"
     ]
    }
   ],
   "source": [
    "for text in result['ocr_texts_per_image']:\n",
    "    print(summarize_ocr_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "74e04ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the extracted metadata in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Iconic Species and Conservation Efforts\",\n",
      "  \"summary\": \"The document discusses two main topics: the first part focuses on three iconic species - the tiger, elephant, and parrot - and their declining populations due to habitat loss, poaching, and human-wildlife conflict. The tiger, a powerful predator native to Asia, is recognized by its distinctive orange coat with black stripes. The elephant, the largest living land animal, is highly intelligent and social, with three species existing today. Elephants are herbivores and play a crucial role in shaping their ecosystems. The parrot, a vibrant and intelligent bird, is known for its colorful feathers and ability to mimic sounds, but many species face threats from habitat loss and human activities. \\nIn the second part, the text shifts to discussing dogs, highlighting their intelligence, loyalty, and companionship. Dogs come in various breeds, each with distinct physical traits and behavioral tendencies shaped by selective breeding. Despite breed influences on energy level, trainability, and temperament, every dog is an individual with its own personality. The text also mentions the importance of conservation efforts for extraordinary birds affected by loss and the illegal pet trade. \\nThe document highlights the importance of conservation and the impact of human activities on iconic species. It also emphasizes the unique characteristics and abilities of each species, such as the tiger's powerful predatory skills, the elephant's high intelligence and social behavior, and the parrot's ability to mimic sounds. \\nFurthermore, the document discusses the various habitats of these species, including forests, grasslands, mangrove swamps, savannas, rainforests, and woodlands. The conservation status of each species is also mentioned, with the tiger being endangered, the elephant being vulnerable, and many parrot species being threatened by habitat loss and human activities. \\nOverall, the document provides a comprehensive overview of iconic species, their characteristics, habitats, and conservation status, as well as the importance of conservation efforts to protect these species and their ecosystems.\",\n",
      "  \"keywords\": \"Tiger, Elephant, Parrot, Habitat loss, Poaching, Human-wildlife conflict, Conservation, Keystone species, Ecosystems, Endangered species, Intelligence, Social behavior, Adaptation, Biodiversity, Dogs, Breeds, Loyalty, Companionship, Social animals, Trainability, Temperament\",\n",
      "  \"topics\": \"Wildlife, Conservation, Ecology, Biology, Zoology\",\n",
      "  \"author\": \"Samyak Mahapatra (second part), None mentioned (first part)\",\n",
      "  \"document_type\": \"Summary report\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "metadata=generate_metadata(response)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec5546f",
   "metadata": {},
   "source": [
    "### Docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "30dd2d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean and standard deviation are two fundamental statistical measures with distinct yet complementary properties. The mean, or average, represents the central tendency of a dataset, providing a single value that summarizes all the numbers in the set. It is sensitive to every value in the data, meaning that even a single extremely large or small value (an outlier) can significantly affect the mean. On the other hand, the standard deviation measures the amount of variation or dispersion in the dataset. A low standard deviation indicates that the data points are closely clustered around the mean, while a high standard deviation suggests that the values are spread out over a wider range. Both the mean and standard deviation are widely used in statistics to describe and compare datasets, and they are especially important in fields such as science, finance, and engineering for understanding patterns, consistency, and reliability in data. \n",
      "The z-test and p-value are important concepts in statistical hypothesis testing, each with distinct properties. The z-test is used to determine whether there is a significant difference between sample and population means, or between two sample means, especially when the sample size is large and the population variance is known. It assumes the data are normally distributed and calculates a z-score, which measures how many standard deviations a data point is from the mean. The p-value, on the other hand, is not a test itself but a probability that quantifies the strength of evidence against the null hypothesis. It represents the likelihood of obtaining a result at least as extreme as the observed one, assuming the null hypothesis is true. A small p-value suggests strong evidence against the null hypothesis, while a large p-value indicates weak evidence. Together, the z-test provides the test statistic and the p-value helps decide whether to reject or fail to reject the null hypothesis, making both essential tools for drawing conclusions from data in scientific research and data analysis.\n",
      "\n",
      "The 67-95-99 rule (more commonly known as the 68-95-99.7 rule or the empirical rule) describes how data is distributed in a normal (Gaussian) distribution. According to this rule, about 68% of the data falls within one standard deviation of the mean, about 95% falls within two standard deviations, and about 99.7% falls within three standard deviations. This means that for a bell-shaped Gaussian curve, the vast majority of values are clustered close to the mean, and very few are found far from it. The rule is widely used in statistics to quickly estimate the spread of data and to identify outliers or unusual observations. It only applies to data that is normally distributed and helps in understanding probabilities, making predictions, and setting thresholds in quality control and risk analysis\n",
      "\n",
      "\n",
      "A log-normal distribution is a continuous probability distribution in which the logarithm of the random variable is normally distributed. In other words, if a variable XX is log-normally distributed, then Y=ln⁡(X)Y=ln(X) follows a normal (Gaussian) distribution. This means that while the normal distribution can take both positive and negative values, the log-normal distribution only takes positive real values, making it especially useful for modeling data that cannot be negative and often displays a right-skewed, long-tailed pattern.\n",
      "The log-normal distribution commonly arises in situations where a quantity results from the multiplicative product of many independent, positive random variables—such as in modeling incomes, biological measurements, stock prices, and certain natural phenomena. Its probability density function is defined for x>0 and is characterized by two parameters: the mean (μμ) and standard deviation (σσ) of the variable’s natural logarithm, not of the variable itself.\n",
      "['Parameters\\n\\na, b integers with b > a\\nnm=b-a+1\\n\\n‘Support ke {a,atl,...,b—1,b}\\nPMF 1\\nn\\nCDF |k| -a+1\\nn\\n\\nMean a+b\\n\\n2\\nMedian a+b\\n\\n2\\n‘Mode N/A\\n\\n', 'Notation | Lognormal( 4, ” )\\n\\nParameters 4 € ( — 00,-+00 ) (logarithm of scale),\\n\\no>0\\n\\nSupport | z €(0,+00)\\n\\nPDF 1 (Ine —p)?\\n——— ep(-\\nsoir 20?\\n\\n', 'vo €0 70 TO 00\\n', 'Z=\\n\\nP17 P2\\n\\nPA-P)Ge+\\n\\n4)\\n\\nnz\\n\\n_ ™P1t\\n\\nr N2P2\\n\\nn, +4\\n\\n+ No\\n', '‘rma to estimate sample standard deviation\\n\\n', '']\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "with open(\"test.docx\", \"rb\") as f:\n",
    "    file_bytes = f.read()\n",
    "\n",
    "uploaded_file = io.BytesIO(file_bytes)\n",
    "uploaded_file.name = \"test.docx\" \n",
    "\n",
    "result = extract_text_and_inline_images(uploaded_file)\n",
    "\n",
    "print(result['text'])\n",
    "# print(result['images'])\n",
    "print(result['ocr_texts_per_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2aafac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "\n",
      "The provided text discusses fundamental statistical concepts, including measures of central tendency and variation, hypothesis testing, and data distribution. The mean and standard deviation are introduced as essential measures, with the mean representing the central tendency of a dataset and the standard deviation measuring variation or dispersion. The z-test and p-value are explained as crucial tools in statistical hypothesis testing, determining significant differences between sample and population means and quantifying evidence against the null hypothesis. The 67-95-99 rule, or empirical rule, describes the distribution of data in a normal distribution, with specific percentages of data falling within one, two, or three standard deviations of the mean.\n",
      "\n",
      "The text also explores the log-normal distribution, a continuous probability distribution where the logarithm of the random variable is normally distributed. This distribution is useful for modeling data that cannot be negative and often displays a right-skewed, long-tailed pattern, commonly arising in situations involving multiplicative products of independent, positive random variables.\n",
      "\n",
      "**Extracted Information:**\n",
      "\n",
      "* **Author:** Not specified\n",
      "* **Important Keywords:**\n",
      "\t+ Mean\n",
      "\t+ Standard deviation\n",
      "\t+ Z-test\n",
      "\t+ P-value\n",
      "\t+ Null hypothesis\n",
      "\t+ 67-95-99 rule (or empirical rule)\n",
      "\t+ Gaussian distribution\n",
      "\t+ Normal distribution\n",
      "\t+ Log-normal distribution\n",
      "\t+ Continuous probability distribution\n",
      "\t+ Right-skewed\n",
      "\t+ Long-tailed pattern\n",
      "* **Key Concepts:**\n",
      "\t+ Central tendency\n",
      "\t+ Variation or dispersion\n",
      "\t+ Statistical hypothesis testing\n",
      "\t+ Data distribution\n",
      "\t+ Outliers or unusual observations\n",
      "\t+ Quality control\n",
      "\t+ Risk analysis\n",
      "\t+ Probability density function\n",
      "* **Fields of Application:**\n",
      "\t+ Science\n",
      "\t+ Finance\n",
      "\t+ Engineering\n",
      "\t+ Economics\n",
      "\t+ Biology\n",
      "\n",
      "**Notable Points:**\n",
      "\n",
      "* The mean is sensitive to outliers, and the standard deviation measures variation or dispersion.\n",
      "* The z-test assumes a normal distribution, and the p-value represents the likelihood of obtaining a result at least as extreme as the observed one.\n",
      "* The 67-95-99 rule applies only to normally distributed data, helping understand probabilities and make predictions.\n",
      "* The log-normal distribution is useful for modeling positive, right-skewed data, commonly arising in economics, biology, and natural phenomena.\n",
      "\n",
      "Overall, the text provides a comprehensive overview of essential statistical concepts, including measures of central tendency, variation, and data distribution, as well as the log-normal distribution and its applications.\n"
     ]
    }
   ],
   "source": [
    "response=summarize_pdf_text(result['text'])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4d53389d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following image appears to be a scanned paragraph describing parameters of a discrete uniform distribution. \n",
      "### Discrete Uniform Distribution Parameters\n",
      "* Parameters: \n",
      "  * a and b are integers where b > a\n",
      "  * n = b - a + 1 (number of possible values)\n",
      "  * Support: {a, a+1, ..., b-1, b}\n",
      "  * PMF (Probability Mass Function): 1/n\n",
      "  * CDF (Cumulative Distribution Function): |k - a + 1|/n\n",
      "* Detected keywords: discrete uniform distribution, parameters, PMF, CDF, mean, median, mode\n",
      "* Detected numbers: none specific, but variables a, b, and n are defined\n",
      "\n",
      "This content describes the parameters of a discrete uniform distribution, describing the support, probability mass function, cumulative distribution function, mean, median, and mode. The mean and median are both calculated as (a + b)/2, while the mode is not applicable (N/A) for this distribution type. The parameters a and b define the range of the distribution, with n representing the total number of possible values. The PMF is uniformly distributed at 1/n, indicating equal probability for each value within the support.\n",
      "The following image appears to be a mathematical description of a Lognormal distribution. \n",
      "### Lognormal Distribution Description\n",
      "* Notation: Lognormal(4, 0)\n",
      "* Parameters: \n",
      "  + μ (logarithm of scale) = 4\n",
      "  + σ > 0\n",
      "* Support: z ∈ (0, +∞)\n",
      "* PDF (Probability Density Function) formula provided, but partially unclear due to OCR extraction issues\n",
      "\n",
      "Detected keywords: Lognormal distribution, μ (mu), σ (sigma), PDF, scale, support.\n",
      "\n",
      "The main idea of this content is to describe the properties of a Lognormal distribution with a specific notation Lognormal(4, 0), where μ = 4 and σ is greater than 0. The support of this distribution is all positive real numbers, indicating that the distribution is defined for values greater than 0. However, the provided PDF formula seems to be partially cut off or unclear, making it difficult to fully understand the intended expression.\n",
      "The following image contains OCR-extracted content that appears to be a numeric sequence. \n",
      "### Numeric Sequence\n",
      "* The sequence includes the numbers: 70, 00\n",
      "* Detected numbers: 70, 00\n",
      "* No specific names, dates, or keywords were detected in the provided content.\n",
      "The main idea of this content is unclear due to the limited and numeric nature of the extracted text. It seems to represent a sequence or a code, but without more context, its purpose or meaning cannot be determined.\n",
      "The following image appears to be a scanned equation or mathematical expression. \n",
      "### Equation Summary\n",
      "* The equation includes various symbols and operators, such as equals signs, plus signs, and parentheses.\n",
      "* Detected symbols: P, N, Z, ™, +, -, =, (, )\n",
      "* Numbers: 17, 2, 4\n",
      "The main idea of this content is unclear due to the nature of the extracted text, which seems to be a fragment of a mathematical equation or expression. The equation includes multiple variables and symbols, but without more context, it's difficult to determine its purpose or meaning. The presence of symbols like ™ suggests it might be related to a specific field or proprietary information, but further clarification is needed to provide a more accurate summary.\n",
      "The following image appears to contain a snippet of statistical terminology. \n",
      "### Statistical Concept\n",
      "* The term 'rma' is mentioned, potentially referring to a method or formula.\n",
      "* 'Estimate sample standard deviation' suggests a statistical procedure.\n",
      "\n",
      "Detected keywords: rma, sample standard deviation.\n",
      "\n",
      "This content seems to refer to a statistical method for estimating the standard deviation of a sample, possibly using a formula or technique abbreviated as 'rma'. However, without more context, the specifics of the 'rma' method or its application are unclear. If 'rma' stands for a specific statistical technique, such as \"random matrix theory\" or another method, its relation to estimating sample standard deviation would depend on the context in which it's used. Further information would be necessary to provide a detailed explanation.\n",
      "No OCR content found to summarize.\n"
     ]
    }
   ],
   "source": [
    "for txt in result['ocr_texts_per_image']:\n",
    "    print(summarize_ocr_text(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5537bdfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted metadata in JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Fundamental Statistical Concepts\",\n",
      "  \"summary\": \"The provided text discusses fundamental statistical concepts, including measures of central tendency and variation, hypothesis testing, and data distribution. The mean and standard deviation are introduced as essential measures, with the mean representing the central tendency of a dataset and the standard deviation measuring variation or dispersion. The z-test and p-value are explained as crucial tools in statistical hypothesis testing, determining significant differences between sample and population means and quantifying evidence against the null hypothesis. The 67-95-99 rule, or empirical rule, describes the distribution of data in a normal distribution, with specific percentages of data falling within one, two, or three standard deviations of the mean.\n",
      "\n",
      "The text also explores the log-normal distribution, a continuous probability distribution where the logarithm of the random variable is normally distributed. This distribution is useful for modeling data that cannot be negative and often displays a right-skewed, long-tailed pattern, commonly arising in situations involving multiplicative products of independent, positive random variables.\n",
      "\n",
      "Key concepts covered include central tendency, variation or dispersion, statistical hypothesis testing, data distribution, outliers or unusual observations, quality control, risk analysis, and probability density function. The mean is sensitive to outliers, and the standard deviation measures variation or dispersion. The z-test assumes a normal distribution, and the p-value represents the likelihood of obtaining a result at least as extreme as the observed one. The 67-95-99 rule applies only to normally distributed data, helping understand probabilities and make predictions. The log-normal distribution is useful for modeling positive, right-skewed data, commonly arising in economics, biology, and natural phenomena.\n",
      "\n",
      "The text provides a comprehensive overview of essential statistical concepts, including measures of central tendency, variation, and data distribution, as well as the log-normal distribution and its applications. The concepts are relevant to various fields, including science, finance, engineering, economics, and biology. The log-normal distribution is particularly useful in these fields, as it can be used to model a wide range of phenomena, from stock prices to population growth.\n",
      "\n",
      "In addition to its practical applications, the text also discusses the theoretical foundations of statistical concepts, including the importance of understanding probability distributions and the role of hypothesis testing in statistical analysis. The text also highlights the importance of considering outliers and unusual observations when analyzing data, as these can have a significant impact on the results of statistical tests.\n",
      "\n",
      "Overall, the text provides a thorough and detailed introduction to fundamental statistical concepts, covering both the theoretical foundations and practical applications of these concepts. The text is relevant to anyone interested in statistics, data analysis, or research methods, and provides a solid foundation for further study in these areas.\n",
      "\n",
      "The text also discusses the importance of statistical analysis in various fields, including science, finance, and engineering. Statistical analysis is used to understand and describe data, to identify patterns and trends, and to make predictions about future outcomes. The text highlights the importance of using statistical concepts, such as hypothesis testing and confidence intervals, to make informed decisions and to evaluate the results of experiments and studies.\n",
      "\n",
      "In conclusion, the text provides a comprehensive and detailed introduction to fundamental statistical concepts, covering both the theoretical foundations and practical applications of these concepts. The text is relevant to anyone interested in statistics, data analysis, or research methods, and provides a solid foundation for further study in these areas.\",\n",
      "  \"keywords\": \"Mean, Standard deviation, Z-test, P\n"
     ]
    }
   ],
   "source": [
    "metadata=generate_metadata(response)\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98adc00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
